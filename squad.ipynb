{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers, serializers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 50\n",
    "H_SIZE = 35\n",
    "POOL_SIZE = 2\n",
    "DROPOUT_RATE = 0.1\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    textVec = np.array([])\n",
    "    for tok in tokens:\n",
    "        textVec = np.append(textVec, glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return textVec.reshape(1, -1)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'])\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(train)\n",
    "val = train[:6000]\n",
    "train = train[6000:]\n",
    "\n",
    "print len(val), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctx = paragraph['context']\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnId = qnaJson['id']\n",
    "            qnVec = text2vec(qnaJson['question'])            \n",
    "            test.append((ctxVec, qnVec, qnId, ctx))\n",
    "  \n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ans_start.append(s)\n",
    "        ans_end.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "        \n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           Variable(np.array(ans_start, dtype=np.int32)).reshape(-1,1), \\\n",
    "           Variable(np.array(ans_end, dtype=np.int32)).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c, q, s, e = get_batch(0, 5, train)\n",
    "print c.shape\n",
    "print q.shape\n",
    "print s.shape\n",
    "print e.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, dropout_ratio, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.h_size = h_size\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "        \n",
    "    def get_para_rep(self, para, ru):\n",
    "        P = []\n",
    "        for i in range(0, para.shape[1], self.wordvec_size):\n",
    "            word = para[:, i:i+self.wordvec_size]\n",
    "            if self.use_gpu: \n",
    "                word.to_gpu()\n",
    "            P.append(F.dropout(ru(word), self.dropout_ratio))\n",
    "            \n",
    "        return F.transpose(F.dstack(P), (0, 1, 2))\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        # context representation\n",
    "        Ds = self.get_para_rep(ctx, self.ctxRU)\n",
    "        \n",
    "        #question representation\n",
    "        Qs = self.get_para_rep(qn, self.qnRU)\n",
    "        \n",
    "        out_ins = []\n",
    "        for i in range(Ds.shape[0]):\n",
    "            D = Ds[i]\n",
    "            Q = Qs[i]\n",
    "            \n",
    "            #attention\n",
    "            affinity = F.matmul(D.T, Q)\n",
    "            A_Q = F.softmax(affinity)\n",
    "            A_D = F.softmax(affinity.T)\n",
    "\n",
    "            C_Q = F.matmul(D, A_Q)\n",
    "            C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "            \n",
    "            out_ins.append(F.concat((D, C_D), axis=0).T)\n",
    "        out_ins = F.transpose(F.dstack(out_ins), (0,2,1))\n",
    "\n",
    "        #output\n",
    "        h_fwd = []\n",
    "        for fout in out_ins:\n",
    "            h_fwd.append(F.dropout(self.outFwd(fout), self.dropout_ratio))\n",
    "        h_fwd = F.dstack(h_fwd)\n",
    "\n",
    "        h_bwd = []\n",
    "        for bout in out_ins[::-1]:\n",
    "            h_bwd.append(F.dropout(self.outBwd(bout), self.dropout_ratio))\n",
    "        h_bwd = F.dstack(h_bwd)\n",
    "        \n",
    "        u_in = F.transpose(F.concat((h_fwd, h_bwd)), (0,2,1))\n",
    "        U = F.dropout(self.outLinear(u_in.reshape(-1, 2*self.h_size)), self.dropout_ratio)\n",
    "        return U.reshape(Ds.shape[0], -1, self.h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctx, qn, ans_start, ans_end = get_batch(0, 5, train)\n",
    "\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE, DROPOUT_RATE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, pool_size, dropout_ratio, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.pool_size = pool_size\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Maxout(2*h_size, h_size, pool_size)\n",
    "            self.M2 = L.Maxout(h_size, h_size, pool_size)\n",
    "            self.M3 = L.Maxout(2*h_size, 1, pool_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        rs = []\n",
    "        for i in range(U.shape[0]):\n",
    "            rs.append(F.broadcast_to(r[i], U[i].shape))\n",
    "        r = F.transpose(F.dstack(rs), (2,0,1))\n",
    "        \n",
    "        m_in = F.concat((U, r), axis=2).reshape(-1, 2*self.h_size)\n",
    "        m1 = F.dropout(self.M1(m_in), self.dropout_ratio)\n",
    "        m2 = F.dropout(self.M2(m1), self.dropout_ratio)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3.reshape(U.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highway = Highway(H_SIZE, POOL_SIZE, DROPOUT_RATE)\n",
    "\n",
    "h = Variable(np.zeros((5, H_SIZE), dtype=np.float32))\n",
    "us = U[:,0].reshape(5, -1)\n",
    "ue = U[:,-1].reshape(5, -1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, pool_size, dropout_ratio, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        \n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, pool_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, pool_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = F.dropout(self.dec_state(F.concat((us,ue))), self.dropout_ratio)\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "        beta = self.HwayEnd(U, h, U[range(U.shape[0]), s], ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE, POOL_SIZE, DROPOUT_RATE)\n",
    "\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, pool_size, dropout_rate, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, dropout_rate, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, pool_size, dropout_rate, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn): \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = np.zeros(U.shape[0], 'i')\n",
    "        end = np.zeros(U.shape[0], 'i') - 1        \n",
    "        for i in range(4):            \n",
    "            us = U[range(U.shape[0]), start]\n",
    "            ue = U[range(U.shape[0]), end]\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "            end = F.argmax(beta, axis=1).data.reshape(-1)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, POOL_SIZE, DROPOUT_RATE)\n",
    "alpha, beta = model(ctx, qn)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(alpha=1e-3)\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, POOL_SIZE, DROPOUT_RATE, USE_GPU)\n",
    "if USE_GPU:\n",
    "    model.to_gpu()\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, opt, epoch_start, epoch_end, batch_size, print_interval):\n",
    "    lossHistory = []\n",
    "    accHistory = []\n",
    "    for epoch in range(epoch_start, epoch_end):\n",
    "        print \"Epoch\", epoch + 1, \"/\", epoch_end\n",
    "        startTime = time.time()\n",
    "        epochScore = 0\n",
    "        epochLoss = 0\n",
    "\n",
    "        shuffle(train)\n",
    "        opt.new_epoch()\n",
    "        \n",
    "        interval_loss = 0\n",
    "        interval_size = 0\n",
    "        interval_start = time.time()\n",
    "        with chainer.using_config('train', True):\n",
    "            for i in range(0, len(train), batch_size):\n",
    "                try:\n",
    "                    ctx, qn, ans_start, ans_end = get_batch(i, batch_size, train)\n",
    "                    if USE_GPU:\n",
    "                        ans_start.to_gpu()\n",
    "                        ans_end.to_gpu()\n",
    "\n",
    "                    model.reset_state()\n",
    "                    pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                    pred_start = pred_start[:ctx.shape[0],:,:]\n",
    "                    pred_end = pred_end[:ctx.shape[0]]\n",
    "\n",
    "                    loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                    loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                    loss = loss_start + loss_end\n",
    "\n",
    "                    interval_loss += loss.data * ctx.shape[0] \n",
    "                    interval_size += ctx.shape[0]\n",
    "                    epochLoss += loss.data * ctx.shape[0] / len(train)\n",
    "                    if i % print_interval == 0:\n",
    "                        print i, \"/\", len(train), \":\", \\\n",
    "                              interval_loss / interval_size, \\\n",
    "                              \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                        interval_loss = 0\n",
    "                        interval_size = 0\n",
    "                        interval_start = time.time()\n",
    "\n",
    "                    s = F.argmax(pred_start, axis=1).data\n",
    "                    e = F.argmax(pred_end, axis=1).data\n",
    "                    for j in range(s.shape[0]):\n",
    "                        if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                            epochScore += 1\n",
    "\n",
    "                    model.cleargrads()\n",
    "                    loss.backward()\n",
    "\n",
    "                    opt.update()\n",
    "                except IndexError as e:\n",
    "                    print \"Error on train index \" + str(i) + \":\", e\n",
    "        \n",
    "        valLoss = 0\n",
    "        valScore = 0\n",
    "        with chainer.using_config('train', False):\n",
    "            for i in range(0, len(val), batch_size):\n",
    "                try:\n",
    "                    ctx, qn, ans_start, ans_end = get_batch(i, batch_size, val)\n",
    "                    if USE_GPU:\n",
    "                        ans_start.to_gpu()\n",
    "                        ans_end.to_gpu()\n",
    "\n",
    "                    model.reset_state()\n",
    "                    pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                    loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                    loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                    valLoss += (loss_start + loss_end).data  * ctx.shape[0] / len(val)\n",
    "\n",
    "                    s = F.argmax(pred_start, axis=1).data\n",
    "                    e = F.argmax(pred_end, axis=1).data\n",
    "                    for j in range(s.shape[0]):\n",
    "                        if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                            valScore += 1\n",
    "                except IndexError as e:\n",
    "                    print \"Error on val index \" + str(i) + \":\", e\n",
    "        \n",
    "        epochAcc = float(epochScore) / len(train)\n",
    "        valAcc = float(valScore) / len(val)\n",
    "        \n",
    "        serializers.save_npz('gpu-epoch' + str(epoch+1) + '.model', model)\n",
    "        print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n",
    "        print \"Train Acc:\", epochAcc, \"Val Acc:\", valAcc, \"Train Loss:\", epochLoss, \"Val Loss:\", valLoss\n",
    "        lossHistory.append((epochLoss, valLoss))\n",
    "        accHistory.append((epochAcc, valAcc))\n",
    "        \n",
    "        histFile = open('trainHist.txt', 'wb')\n",
    "        histFile.write(str(lossHistory) + '\\n')\n",
    "        histFile.write(str(accHistory) + '\\n')\n",
    "        histFile.close()\n",
    "        \n",
    "    return lossHistory, accHistory\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#serializers.load_npz('gpu-epoch6.model', model)\n",
    "lossHistory, accHistory = train_model(model, opt, 0, 1, 48, 1000)\n",
    "\n",
    "print lossHistory\n",
    "print accHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ids = []\n",
    "    ctxStrs = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ids.append(s)\n",
    "        ctxStrs.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "\n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           ids, \\\n",
    "           ctxStrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(test_batch_size, test_print_interval, model_file,out_file):    \n",
    "    serializers.load_npz(model_file, model)\n",
    "\n",
    "    f = open(out_file, 'wb')\n",
    "    out = csv.writer(f)\n",
    "    out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    for i in range(0, len(test), test_batch_size):\n",
    "        ctx, qn, qnId, ctxStr = get_test_batch(i, test_batch_size, test)\n",
    "        model.reset_state()\n",
    "        start, end = model(ctx, qn)\n",
    "\n",
    "        for j in range(len(qnId)):\n",
    "            contextTokens = word_tokenize(ctxStr[j])\n",
    "\n",
    "            s = F.argmax(start[j]).data\n",
    "            e = F.argmax(end[j]).data\n",
    "\n",
    "            s = min(s, len(contextTokens)-1)\n",
    "            e = max(e, s)\n",
    "            e = min(e, len(contextTokens)-1)        \n",
    "\n",
    "            ans = \"\"\n",
    "            for k in range(s, e + 1):\n",
    "                ans += contextTokens[k] + \" \"\n",
    "\n",
    "            out.writerow([qnId[j], normalize_answer(ans).encode('utf-8')])\n",
    "\n",
    "        if i % test_print_interval == 0:\n",
    "            print i, \"/\", len(test), \"(\" + str(time.time() - startTime) + \"s)\"\n",
    "            startTime = time.time()\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batch_size = 48\n",
    "test_print_interval = 1000\n",
    "\n",
    "with chainer.using_config('train', False):\n",
    "    for i in range(1,2):\n",
    "        test_model(test_batch_size, test_print_interval, 'gpu-epoch' + str(i) + '.model','pred' + str(i) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
