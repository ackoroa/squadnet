{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers, serializers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 300\n",
    "H_SIZE = 200\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    textVec = np.array([])\n",
    "    for tok in tokens:\n",
    "        textVec = np.append(textVec, glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return textVec.reshape(1, -1)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61379\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        ctxLen = len(paragraph['context'])\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'].lower())\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "            \n",
    "len_train = len(train)\n",
    "print len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7984\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        data = {}\n",
    "        data['context'] = paragraph['context']\n",
    "        data['contextVec'] = text2vec(paragraph['context'])\n",
    "        data['qna'] = []\n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qna = {}\n",
    "            qna['id'] = qnaJson['id']\n",
    "            qna['question'] = qnaJson['question']\n",
    "            qna['questionVec'] = text2vec(qnaJson['question'].lower())\n",
    "            data['qna'].append(qna)\n",
    "        test.append(data)\n",
    "\n",
    "print len(test)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i, batch_size):\n",
    "    j = min(i + batch_size, len_train)\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = train[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ans_start.append(s)\n",
    "        ans_end.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(cmax, q.shape[1])\n",
    "        \n",
    "    cVec = np.zeros((batch_size, cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((batch_size, qmax), dtype=np.float32)        \n",
    "    for i in range(batch_size):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           Variable(np.array(ans_start, dtype=np.int32)).reshape(-1,1), \\\n",
    "           Variable(np.array(ans_end, dtype=np.int32)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "        \n",
    "    def get_para_rep(self, para, ru):\n",
    "        P = []\n",
    "        for i in range(0, para.shape[1], self.wordvec_size):\n",
    "            word = para[:, i:i+self.wordvec_size]\n",
    "            if self.use_gpu: \n",
    "                word.to_gpu()\n",
    "            P.append(ru(word))\n",
    "        return F.transpose(F.dstack(P), (0, 1, 2))\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        # context representation\n",
    "        Ds = self.get_para_rep(ctx, self.ctxRU)\n",
    "        \n",
    "        #question representation\n",
    "        Qs = self.get_para_rep(qn, self.qnRU)\n",
    "        \n",
    "        out_ins = []\n",
    "        for i in range(Ds.shape[0]):\n",
    "            D = Ds[i]\n",
    "            Q = Qs[i]\n",
    "            \n",
    "            #attention\n",
    "            affinity = F.matmul(D.T, Q)\n",
    "            A_Q = F.softmax(affinity)\n",
    "            A_D = F.softmax(affinity.T)\n",
    "\n",
    "            C_Q = F.matmul(D, A_Q)\n",
    "            C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "            \n",
    "            out_ins.append(F.concat((D, C_D), axis=0).T)\n",
    "        out_ins = F.transpose(F.dstack(out_ins), (0,2,1))\n",
    "\n",
    "        #output\n",
    "        h_fwd = []\n",
    "        for fout in out_ins:\n",
    "            h_fwd.append(self.outFwd(fout))\n",
    "        h_fwd = F.dstack(h_fwd)\n",
    "\n",
    "        h_bwd = []\n",
    "        for bout in out_ins[::-1]:\n",
    "            h_bwd.append(self.outBwd(bout))\n",
    "        h_bwd = F.dstack(h_bwd)\n",
    "        \n",
    "        u_in = F.transpose(F.concat((h_fwd, h_bwd)), (0,2,1))\n",
    "        U = self.outLinear(u_in.reshape(-1, 2*self.h_size))\n",
    "        return U.reshape(Ds.shape[0], -1, self.h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 200)\n"
     ]
    }
   ],
   "source": [
    "ctx, qn, ans_start, ans_end = get_batch(0, 5)\n",
    "\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Linear(2*h_size, h_size)\n",
    "            self.M2 = L.Linear(h_size, h_size)\n",
    "            self.M3 = L.Linear(2*h_size, 1)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        rs = []\n",
    "        for i in range(U.shape[0]):\n",
    "            rs.append(F.broadcast_to(r[i], U[i].shape))\n",
    "        r = F.transpose(F.dstack(rs), (2,0,1))\n",
    "        \n",
    "        m_in = F.concat((U, r), axis=2).reshape(-1, 2*self.h_size)\n",
    "        m1 = self.M1(m_in)\n",
    "        m2 = self.M2(m1)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3.reshape(U.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1)\n"
     ]
    }
   ],
   "source": [
    "highway = Highway(H_SIZE)\n",
    "\n",
    "h = Variable(np.zeros((5, H_SIZE), dtype=np.float32))\n",
    "us = U[:,0].reshape(5, -1)\n",
    "ue = U[:,-1].reshape(5, -1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = self.dec_state(F.concat((us,ue)))\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "        beta = self.HwayEnd(U, h, U[range(U.shape[0]), s], ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1) [[0 0 0 0 0]]\n",
      "(5, 125, 1) [[123 123 123 123 123]]\n"
     ]
    }
   ],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE)\n",
    "\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn): \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = np.zeros(U.shape[0], 'i')\n",
    "        end = np.zeros(U.shape[0], 'i') - 1        \n",
    "        for i in range(3):            \n",
    "            us = U[range(U.shape[0]), start]\n",
    "            ue = U[range(U.shape[0]), end]\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "            end = F.argmax(beta, axis=1).data.reshape(-1)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1) [[108 108 108 108 108]]\n",
      "(5, 125, 1) [[51 51 51 51 51]]\n"
     ]
    }
   ],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE)\n",
    "alpha, beta = model(ctx, qn)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodynamicAttention uses GPU True\n",
      "Highway uses GPU True\n",
      "Highway uses GPU True\n",
      "DynamicPointincDecoded uses GPU True\n",
      "SquadNet uses GPU True\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(alpha=1e-3)\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, USE_GPU)\n",
    "if USE_GPU:\n",
    "    model.to_gpu()\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, epoch_start, epoch_end, batch_size, print_interval):\n",
    "    for epoch in range(epoch_start, epoch_end+1):\n",
    "        print \"Epoch\", epoch + 1, \"/\", n_epoch\n",
    "        startTime = time.time()\n",
    "\n",
    "        opt.new_epoch()\n",
    "        \n",
    "        interval_loss = 0\n",
    "        interval_start = time.time()\n",
    "        for i in range(0, len_train, batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                loss = loss_start + loss_end\n",
    "\n",
    "                interval_loss += loss.data\n",
    "                if i % print_interval == 0:\n",
    "                    print i, \"/\", len_train, \":\", \\\n",
    "                          interval_loss, \\\n",
    "                          \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                    interval_loss = 0\n",
    "                    interval_start = time.time()\n",
    "\n",
    "                model.cleargrads()\n",
    "                loss.backward()\n",
    "\n",
    "                opt.update()\n",
    "            except IndexError as e:\n",
    "                print \"Error on index \" + str(i) + \":\", e\n",
    "        print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n",
    "        serializers.save_npz('gpu-epoch' + str(epoch) + '.model', model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n",
      "0 / 61379 : 10.5406913757 (2.26723814011s)\n",
      "1000 / 61379 : 98.0884552002 (46.7571570873s)\n",
      "2000 / 61379 : 96.8072509766 (44.9427349567s)\n",
      "3000 / 61379 : 95.5199508667 (51.7055549622s)\n",
      "4000 / 61379 : 87.2269592285 (50.9664750099s)\n",
      "5000 / 61379 : 86.1722946167 (48.1180589199s)\n",
      "6000 / 61379 : 86.2194137573 (44.4488229752s)\n",
      "7000 / 61379 : 83.4306411743 (52.9158499241s)\n",
      "8000 / 61379 : 90.6543731689 (55.6347739697s)\n",
      "9000 / 61379 : 85.1919784546 (44.203099966s)\n",
      "10000 / 61379 : 87.9598083496 (50.2284829617s)\n",
      "11000 / 61379 : 80.7679290771 (44.71124506s)\n",
      "12000 / 61379 : 88.1275863647 (55.7020790577s)\n",
      "13000 / 61379 : 80.8079452515 (45.524091959s)\n",
      "14000 / 61379 : 85.689125061 (73.5832419395s)\n",
      "15000 / 61379 : 82.4831924438 (48.8700990677s)\n",
      "16000 / 61379 : 79.7526016235 (47.0941290855s)\n",
      "17000 / 61379 : 82.8972396851 (54.9411220551s)\n",
      "18000 / 61379 : 80.2893676758 (61.2505581379s)\n",
      "19000 / 61379 : 80.5836029053 (50.5075311661s)\n",
      "20000 / 61379 : 79.1858825684 (62.0834269524s)\n",
      "21000 / 61379 : 73.7223358154 (53.4724228382s)\n",
      "22000 / 61379 : 80.7936172485 (59.868997097s)\n",
      "23000 / 61379 : 74.6721420288 (52.7262289524s)\n",
      "24000 / 61379 : 80.5173110962 (45.8974759579s)\n",
      "25000 / 61379 : 80.4170455933 (57.8471679688s)\n",
      "26000 / 61379 : 77.162361145 (47.2351789474s)\n",
      "27000 / 61379 : 74.1366119385 (67.9298629761s)\n",
      "28000 / 61379 : 72.5688781738 (43.4258759022s)\n",
      "29000 / 61379 : 73.8683395386 (45.4414927959s)\n",
      "30000 / 61379 : 78.6752471924 (54.1841061115s)\n",
      "31000 / 61379 : 73.5723266602 (48.7695529461s)\n",
      "32000 / 61379 : 74.2891235352 (58.4174909592s)\n",
      "33000 / 61379 : 63.609085083 (41.0624680519s)\n",
      "34000 / 61379 : 73.8619766235 (50.3263020515s)\n",
      "35000 / 61379 : 72.6587524414 (75.6336078644s)\n",
      "36000 / 61379 : 79.5195922852 (45.2529420853s)\n",
      "37000 / 61379 : 73.5127639771 (48.2032670975s)\n",
      "38000 / 61379 : 77.7737350464 (56.3851611614s)\n",
      "39000 / 61379 : 73.5267562866 (48.1067349911s)\n",
      "40000 / 61379 : 71.0705413818 (56.8291618824s)\n",
      "41000 / 61379 : 62.9629859924 (41.3073511124s)\n",
      "42000 / 61379 : 70.5569229126 (57.0145609379s)\n",
      "43000 / 61379 : 68.5350799561 (44.3292939663s)\n",
      "44000 / 61379 : 71.8696517944 (42.7706911564s)\n",
      "45000 / 61379 : 68.7308883667 (45.428812027s)\n",
      "46000 / 61379 : 74.333190918 (56.1241099834s)\n",
      "47000 / 61379 : 67.8876953125 (50.8172779083s)\n",
      "48000 / 61379 : 69.9341049194 (48.188986063s)\n",
      "49000 / 61379 : 67.194694519 (36.6855151653s)\n",
      "50000 / 61379 : 65.143157959 (41.0513489246s)\n",
      "51000 / 61379 : 66.9047698975 (40.0642490387s)\n",
      "52000 / 61379 : 68.4478378296 (45.0787670612s)\n",
      "53000 / 61379 : 72.2608108521 (48.6480278969s)\n",
      "54000 / 61379 : 58.7009353638 (53.2966601849s)\n",
      "55000 / 61379 : 67.328956604 (51.0272569656s)\n",
      "56000 / 61379 : 68.5238189697 (56.9981281757s)\n",
      "57000 / 61379 : 68.6794815063 (48.7826650143s)\n",
      "58000 / 61379 : 69.0222549438 (42.0538418293s)\n",
      "59000 / 61379 : 67.6044845581 (42.6148869991s)\n",
      "60000 / 61379 : 67.544380188 (62.2045798302s)\n",
      "61000 / 61379 : 71.6217651367 (60.1104488373s)\n",
      "Error on index 61300: list index out of range\n",
      "Epoch completed in 3122.7520659 seconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'serializers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-268cb512da6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-f57aa9ff62b3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, opt, n_epoch, batch_size, print_interval)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Error on index \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Epoch completed in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mserializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu-epoch'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'serializers' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(model, opt, 1, 5, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_npz('gpu.model', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(i):    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    \n",
    "    testData = test[i]\n",
    "    for qna in testData['qna']:\n",
    "        ctx.append(testData['contextVec'])\n",
    "        qn.append(qna['questionVec'])\n",
    "        cmax = max(cmax, testData['contextVec'].shape[1])\n",
    "        qmax = max(cmax, qna['questionVec'].shape[1])\n",
    "    \n",
    "    batch_size = len(qn)\n",
    "    cVec = np.zeros((batch_size, cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((batch_size, qmax), dtype=np.float32)        \n",
    "    for i in range(batch_size):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), Variable(qVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 7984 (1.47932910919s)\n",
      "100 / 7984 (73.9849860668s)\n",
      "200 / 7984 (49.1458120346s)\n",
      "300 / 7984 (57.2862179279s)\n",
      "400 / 7984 (50.1581408978s)\n",
      "500 / 7984 (61.8074829578s)\n"
     ]
    }
   ],
   "source": [
    "f = open('pred.csv', 'wb')\n",
    "out = csv.writer(f)\n",
    "out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "startTime = time.time()\n",
    "for idx, t in enumerate(test):\n",
    "    contextTokens = word_tokenize(t['context'])\n",
    "    \n",
    "    ctx, qn = get_test_batch(idx)\n",
    "    model.reset_state()\n",
    "    start, end = model(ctx, qn)\n",
    "    \n",
    "    for idx_qna, qna in enumerate(t['qna']):\n",
    "        id = qna['id']\n",
    "      \n",
    "        s = F.argmax(start[idx_qna]).data\n",
    "        e = F.argmax(end[idx_qna]).data\n",
    "        \n",
    "        s = min(s, len(contextTokens)-1)\n",
    "        e = max(e, s)\n",
    "        e = min(e, len(contextTokens)-1)        \n",
    "        \n",
    "        ans = \"\"\n",
    "        for i in range(s, e + 1):\n",
    "            ans += contextTokens[i] + \" \"\n",
    "        \n",
    "        out.writerow([id, normalize_answer(ans).encode('utf-8')])\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print idx, \"/\", len(test), \"(\" + str(time.time() - startTime) + \"s)\"\n",
    "        startTime = time.time()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
