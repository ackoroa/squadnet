{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "\n",
    "import numpy as np\n",
    "import cupy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 300\n",
    "H_SIZE = 200\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    textVec = []\n",
    "    for tok in tokens:\n",
    "        textVec.append(glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return np.vstack(textVec)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61379\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        ctxLen = len(paragraph['context'])\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'].lower())\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "print len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        data = {}\n",
    "        data['context'] = paragraph['context']\n",
    "        data['contextVec'] = text2vec(paragraph['context'])\n",
    "        data['qna'] = []\n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qna = {}\n",
    "            qna['id'] = qnaJson['id']\n",
    "            qna['question'] = qnaJson['question']\n",
    "            qna['questionVec'] = text2vec(qnaJson['question'].lower())\n",
    "            data['qna'].append(qna)\n",
    "        test.append(data)\n",
    "\n",
    "print len(test)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "            \n",
    "    def __call__(self, context, question):\n",
    "        if self.use_gpu:\n",
    "            context.to_gpu()\n",
    "            question.to_gpu()\n",
    "        \n",
    "        # context representation\n",
    "        D = []\n",
    "        for word in ctx:\n",
    "            D.append(self.ctxRU(word.reshape(1,-1)))\n",
    "        D = F.vstack(D).T\n",
    "        \n",
    "        #question representation\n",
    "        Q = []\n",
    "        for word in qn:\n",
    "            Q.append(self.qnRU(word.reshape(1,-1)))\n",
    "        Q = F.vstack(Q).T\n",
    "        \n",
    "        #attention\n",
    "        affinity = F.matmul(D.T, Q)\n",
    "        A_Q = F.softmax(affinity)\n",
    "        A_D = F.softmax(affinity.T)\n",
    "        \n",
    "        C_Q = F.matmul(D, A_Q)\n",
    "        C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "        \n",
    "        #output\n",
    "        out_in = F.concat((D, C_D), axis=0).T \n",
    "        h_fwd = []\n",
    "        for fout in out_in:\n",
    "            h_fwd.append(self.outFwd(fout.reshape(1,-1)))\n",
    "        h_fwd = F.vstack(h_fwd)\n",
    "            \n",
    "        h_bwd = []\n",
    "        for bout in out_in[::-1]:\n",
    "            h_bwd.append(self.outBwd(bout.reshape(1,-1)))\n",
    "        h_bwd = F.vstack(h_bwd)\n",
    "\n",
    "        U = self.outLinear(F.concat((h_fwd, h_bwd)))\n",
    "        return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 200)\n",
      "variable([[-0.02166628  0.02317781 -0.00961676 ...,  0.00090812  0.01186791\n",
      "           -0.01885116]\n",
      "          [-0.02203519  0.03849705 -0.02644069 ...,  0.01507787  0.01123061\n",
      "           -0.03821265]\n",
      "          [-0.02479432  0.05541698 -0.03499736 ...,  0.00275426  0.00463762\n",
      "           -0.06173932]\n",
      "          ..., \n",
      "          [-0.00337664 -0.12541448 -0.1532461  ...,  0.12494828  0.07163908\n",
      "           -0.42345271]\n",
      "          [ 0.00877049 -0.13439099 -0.17650859 ...,  0.11109424  0.08447176\n",
      "           -0.396117  ]\n",
      "          [ 0.00605384 -0.14172652 -0.17810073 ...,  0.07499248  0.09153669\n",
      "           -0.37307736]])\n"
     ]
    }
   ],
   "source": [
    "ctx = Variable(train[0][0])\n",
    "qn = Variable(train[0][1])\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape\n",
    "print U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Linear(2*h_size, h_size)\n",
    "            self.M2 = L.Linear(h_size, h_size)\n",
    "            self.M3 = L.Linear(2*h_size, 1)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        m1 = self.M1(F.concat((U, F.broadcast_to(r, U.shape))))\n",
    "        m2 = self.M2(m1)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 1)\n"
     ]
    }
   ],
   "source": [
    "highway = Highway(H_SIZE)\n",
    "\n",
    "h = Variable(np.zeros((1,H_SIZE), dtype=np.float32))\n",
    "us = U[0].reshape(1,-1)\n",
    "ue = U[-1].reshape(1,-1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = self.dec_state(F.concat((us,ue)))\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha).data\n",
    "        beta = self.HwayEnd(U, h, U[s].reshape(1,-1), ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 1) variable(26)\n",
      "(125, 1) variable(38)\n"
     ]
    }
   ],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE)\n",
    "\n",
    "us = U[0].reshape(1,-1)\n",
    "ue = U[-1].reshape(1,-1)\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha)\n",
    "print beta.shape, F.argmax(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        if self.use_gpu:\n",
    "            ctx.to_gpu()\n",
    "            qn.to_gpu()\n",
    "        \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = 0\n",
    "        end = -1\n",
    "        for i in range(3):            \n",
    "            us = U[start].reshape(1, -1)\n",
    "            ue = U[end].reshape(1, -1)\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha).data\n",
    "            end = F.argmax(beta).data\n",
    "        return alpha.reshape(1, -1), beta.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 1)\n",
      "(125, 1)\n"
     ]
    }
   ],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE)\n",
    "alpha. beta = model(ctx, qn)\n",
    "print alpha.shape\n",
    "print beta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodynamicAttention uses GPU True\n",
      "Highway uses GPU True\n",
      "Highway uses GPU True\n",
      "DynamicPointincDecoded uses GPU True\n",
      "SquadNet uses GPU True\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam()\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, USE_GPU)\n",
    "model.to_gpu()\n",
    "\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 5\n",
      "0 / 61379 : 9.58268737793 (1.50776696205s)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 5\n",
    "PRINT_INTERVAL = 1000\n",
    "\n",
    "len_train = len(train)\n",
    "for epoch in range(N_EPOCH):\n",
    "    print \"Epoch\", epoch + 1, \"/\", N_EPOCH\n",
    "    startTime = time.time()\n",
    "    \n",
    "    interval_loss = 0\n",
    "    interval_start = time.time()\n",
    "    for i in range(len_train):\n",
    "        try:\n",
    "            ctx, qn, ans_start, ans_end = train[i]\n",
    "            ctx = Variable(ctx)\n",
    "            qn = Variable(qn)\n",
    "            \n",
    "            model.reset_state()\n",
    "            pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "            loss_start = F.softmax_cross_entropy(pred_start, cupy.array([ans_start], dtype=np.int32))\n",
    "            loss_end = F.softmax_cross_entropy(pred_end, cupy.array([ans_end], dtype=np.int32))\n",
    "            loss = loss_start + loss_end\n",
    "            \n",
    "            interval_loss += loss.data\n",
    "            if i % PRINT_INTERVAL == 0:\n",
    "                print i, \"/\", len_train, \":\", interval_loss, \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                interval_loss = 0\n",
    "                interval_start = time.time()\n",
    "\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "\n",
    "            opt.update()\n",
    "        except IndexError as e:\n",
    "            print \"Error on index \" + str(i) + \":\", e\n",
    "    print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('pred.csv', 'wb')\n",
    "out = csv.writer(f)\n",
    "out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "for t in test:\n",
    "    ctx = word_tokenize(t['context'])\n",
    "    ctxVec = t['contextVec']\n",
    "    \n",
    "    for qna in t['qna']:\n",
    "        id = qna['id']\n",
    "        qn = qna['question']\n",
    "        qnVec = qna['questionVec']\n",
    "        \n",
    "        model.reset_state()\n",
    "        start, end = model(ctxVec, qnVec)\n",
    "        start = F.argmax(start).data\n",
    "        end = F.argmax(end).data\n",
    "        \n",
    "        ans = \"\"\n",
    "        for i in range(start, end + 1):\n",
    "            ans += ctx[i] + \" \"\n",
    "        \n",
    "        out.writerow([id, normalize_answer(ans).encode('utf-8')])\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
