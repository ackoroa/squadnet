{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers, serializers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 300\n",
    "H_SIZE = 200\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    textVec = np.array([])\n",
    "    for tok in tokens:\n",
    "        textVec = np.append(textVec, glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return textVec.reshape(1, -1)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61379"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'])\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 55379\n"
     ]
    }
   ],
   "source": [
    "shuffle(train)\n",
    "val = train[:6000]\n",
    "train = train[6000:]\n",
    "\n",
    "print len(val), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36790"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctx = paragraph['context']\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnId = qnaJson['id']\n",
    "            qnVec = text2vec(qnaJson['question'])            \n",
    "            test.append((ctxVec, qnVec, qnId, ctx))\n",
    "  \n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ans_start.append(s)\n",
    "        ans_end.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "        \n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           Variable(np.array(ans_start, dtype=np.int32)).reshape(-1,1), \\\n",
    "           Variable(np.array(ans_end, dtype=np.int32)).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 63300)\n",
      "(5, 3900)\n",
      "(5, 1)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "c, q, s, e = get_batch(0, 5, train)\n",
    "print c.shape\n",
    "print q.shape\n",
    "print s.shape\n",
    "print e.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "        \n",
    "    def get_para_rep(self, para, ru):\n",
    "        P = []\n",
    "        for i in range(0, para.shape[1], self.wordvec_size):\n",
    "            word = para[:, i:i+self.wordvec_size]\n",
    "            if self.use_gpu: \n",
    "                word.to_gpu()\n",
    "            P.append(ru(word))\n",
    "        return F.transpose(F.dstack(P), (0, 1, 2))\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        # context representation\n",
    "        Ds = self.get_para_rep(ctx, self.ctxRU)\n",
    "        \n",
    "        #question representation\n",
    "        Qs = self.get_para_rep(qn, self.qnRU)\n",
    "        \n",
    "        out_ins = []\n",
    "        for i in range(Ds.shape[0]):\n",
    "            D = Ds[i]\n",
    "            Q = Qs[i]\n",
    "            \n",
    "            #attention\n",
    "            affinity = F.matmul(D.T, Q)\n",
    "            A_Q = F.softmax(affinity)\n",
    "            A_D = F.softmax(affinity.T)\n",
    "\n",
    "            C_Q = F.matmul(D, A_Q)\n",
    "            C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "            \n",
    "            out_ins.append(F.concat((D, C_D), axis=0).T)\n",
    "        out_ins = F.transpose(F.dstack(out_ins), (0,2,1))\n",
    "\n",
    "        #output\n",
    "        h_fwd = []\n",
    "        for fout in out_ins:\n",
    "            h_fwd.append(self.outFwd(fout))\n",
    "        h_fwd = F.dstack(h_fwd)\n",
    "\n",
    "        h_bwd = []\n",
    "        for bout in out_ins[::-1]:\n",
    "            h_bwd.append(self.outBwd(bout))\n",
    "        h_bwd = F.dstack(h_bwd)\n",
    "        \n",
    "        u_in = F.transpose(F.concat((h_fwd, h_bwd)), (0,2,1))\n",
    "        U = self.outLinear(u_in.reshape(-1, 2*self.h_size))\n",
    "        return U.reshape(Ds.shape[0], -1, self.h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 211, 200)\n"
     ]
    }
   ],
   "source": [
    "ctx, qn, ans_start, ans_end = get_batch(0, 5, train)\n",
    "\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Linear(2*h_size, h_size)\n",
    "            self.M2 = L.Linear(h_size, h_size)\n",
    "            self.M3 = L.Linear(2*h_size, 1)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        rs = []\n",
    "        for i in range(U.shape[0]):\n",
    "            rs.append(F.broadcast_to(r[i], U[i].shape))\n",
    "        r = F.transpose(F.dstack(rs), (2,0,1))\n",
    "        \n",
    "        m_in = F.concat((U, r), axis=2).reshape(-1, 2*self.h_size)\n",
    "        m1 = self.M1(m_in)\n",
    "        m2 = self.M2(m1)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3.reshape(U.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 211, 1)\n"
     ]
    }
   ],
   "source": [
    "highway = Highway(H_SIZE)\n",
    "\n",
    "h = Variable(np.zeros((5, H_SIZE), dtype=np.float32))\n",
    "us = U[:,0].reshape(5, -1)\n",
    "ue = U[:,-1].reshape(5, -1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = self.dec_state(F.concat((us,ue)))\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "        beta = self.HwayEnd(U, h, U[range(U.shape[0]), s], ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 211, 1) [[158  70  55  53 119]]\n",
      "(5, 211, 1) [[56  5 17 39 13]]\n"
     ]
    }
   ],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE)\n",
    "\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn): \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = np.zeros(U.shape[0], 'i')\n",
    "        end = np.zeros(U.shape[0], 'i') - 1        \n",
    "        for i in range(3):            \n",
    "            us = U[range(U.shape[0]), start]\n",
    "            ue = U[range(U.shape[0]), end]\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "            end = F.argmax(beta, axis=1).data.reshape(-1)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 211, 1) [[199   0  45 208   0]]\n",
      "(5, 211, 1) [[207 177 145  34 192]]\n"
     ]
    }
   ],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE)\n",
    "alpha, beta = model(ctx, qn)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodynamicAttention uses GPU True\n",
      "Highway uses GPU True\n",
      "Highway uses GPU True\n",
      "DynamicPointincDecoded uses GPU True\n",
      "SquadNet uses GPU True\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(alpha=1e-3)\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, USE_GPU)\n",
    "if USE_GPU:\n",
    "    model.to_gpu()\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, epoch_start, epoch_end, batch_size, print_interval):\n",
    "    for epoch in range(epoch_start, epoch_end):\n",
    "        print \"Epoch\", epoch + 1, \"/\", epoch_end\n",
    "        startTime = time.time()\n",
    "        epochScore = 0\n",
    "\n",
    "        opt.new_epoch()\n",
    "        \n",
    "        interval_loss = 0\n",
    "        interval_start = time.time()\n",
    "        for i in range(0, len(train), batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size, train)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "                \n",
    "                pred_start = pred_start[:ctx.shape[0],:,:]\n",
    "                pred_end = pred_end[:ctx.shape[0]]\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                loss = loss_start + loss_end\n",
    "\n",
    "                interval_loss += loss.data\n",
    "                if i % print_interval == 0:\n",
    "                    print i, \"/\", len(train), \":\", \\\n",
    "                          interval_loss, \\\n",
    "                          \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                    interval_loss = 0\n",
    "                    interval_start = time.time()\n",
    "                \n",
    "                s = F.argmax(pred_start, axis=1).data\n",
    "                e = F.argmax(pred_end, axis=1).data\n",
    "                for j in range(s.shape[0]):\n",
    "                    if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                        epochScore += 1\n",
    "\n",
    "                model.cleargrads()\n",
    "                loss.backward()\n",
    "\n",
    "                opt.update()\n",
    "            except IndexError as e:\n",
    "                print \"Error on train index \" + str(i) + \":\", e\n",
    "        \n",
    "        valLoss = 0\n",
    "        valScore = 0\n",
    "        for i in range(0, len(val), batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size, val)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                valLoss += (loss_start + loss_end).data[0]\n",
    "                \n",
    "                s = F.argmax(pred_start, axis=1).data\n",
    "                e = F.argmax(pred_end, axis=1).data\n",
    "                for j in range(s.shape[0]):\n",
    "                    if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                        valScore += 1\n",
    "            except IndexError as e:\n",
    "                print \"Error on val index \" + str(i) + \":\", e\n",
    "        \n",
    "        epochAcc = float(epochScore) / len(train)\n",
    "        valAcc = float(valScore) / len(val)\n",
    "        \n",
    "        serializers.save_npz('gpu-epoch' + str(epoch+1) + '.model', model)\n",
    "        print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n",
    "        print \"Train Acc:\", epochAcc, \"Val Acc:\", valAcc, \"Val Loss:\", valLoss      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 4\n",
      "0 / 55379 : 12.1828937531 (3.52974891663s)\n",
      "1000 / 55379 : 100.564147949 (65.8244030476s)\n",
      "2000 / 55379 : 94.4896011353 (66.1620030403s)\n",
      "3000 / 55379 : 91.713218689 (63.6191749573s)\n",
      "4000 / 55379 : 88.0624389648 (57.8861138821s)\n",
      "5000 / 55379 : 86.1820297241 (64.9297659397s)\n",
      "6000 / 55379 : 86.2587432861 (71.9238700867s)\n",
      "7000 / 55379 : 84.1076507568 (74.4954352379s)\n",
      "8000 / 55379 : 82.9869232178 (71.1950030327s)\n",
      "9000 / 55379 : 84.1689682007 (66.6713130474s)\n",
      "10000 / 55379 : 80.9822540283 (77.1377270222s)\n",
      "11000 / 55379 : 81.5206298828 (80.8533189297s)\n",
      "12000 / 55379 : 80.4490432739 (64.5426049232s)\n",
      "13000 / 55379 : 78.1296234131 (57.3346841335s)\n",
      "14000 / 55379 : 79.5576705933 (68.0029051304s)\n",
      "15000 / 55379 : 76.6008071899 (64.2937381268s)\n",
      "16000 / 55379 : 76.0832519531 (57.8295772076s)\n",
      "17000 / 55379 : 75.0408172607 (76.0438868999s)\n",
      "18000 / 55379 : 76.0847396851 (59.5579409599s)\n",
      "19000 / 55379 : 75.3709030151 (59.9746899605s)\n",
      "20000 / 55379 : 75.7866516113 (71.0160360336s)\n",
      "21000 / 55379 : 74.1783676147 (67.3440129757s)\n",
      "22000 / 55379 : 73.2698287964 (62.4045209885s)\n",
      "23000 / 55379 : 72.9801101685 (63.9174599648s)\n",
      "24000 / 55379 : 74.6376342773 (59.4477858543s)\n",
      "25000 / 55379 : 72.0669555664 (72.0917861462s)\n",
      "26000 / 55379 : 72.2577362061 (71.015499115s)\n",
      "27000 / 55379 : 71.5917663574 (63.165184021s)\n",
      "28000 / 55379 : 70.2787628174 (70.2458510399s)\n",
      "29000 / 55379 : 69.7615966797 (56.0845401287s)\n",
      "30000 / 55379 : 70.243598938 (70.3068709373s)\n",
      "31000 / 55379 : 69.5507507324 (66.5218119621s)\n",
      "32000 / 55379 : 70.6021499634 (70.2033679485s)\n",
      "33000 / 55379 : 68.4808654785 (80.3916990757s)\n",
      "34000 / 55379 : 69.7923583984 (60.0687701702s)\n",
      "35000 / 55379 : 69.3215026855 (71.4262268543s)\n",
      "36000 / 55379 : 70.4622497559 (74.8487319946s)\n",
      "37000 / 55379 : 67.071472168 (60.1910150051s)\n",
      "38000 / 55379 : 69.6418380737 (61.3304059505s)\n",
      "39000 / 55379 : 68.9955596924 (63.5596148968s)\n",
      "40000 / 55379 : 69.1809768677 (76.8706028461s)\n",
      "41000 / 55379 : 68.7568664551 (62.2766129971s)\n",
      "42000 / 55379 : 67.9228439331 (57.7853550911s)\n",
      "43000 / 55379 : 67.2242050171 (72.2961997986s)\n",
      "44000 / 55379 : 66.1119766235 (61.0605061054s)\n",
      "45000 / 55379 : 66.6674575806 (70.0080258846s)\n",
      "46000 / 55379 : 65.8594665527 (66.3507711887s)\n",
      "47000 / 55379 : 67.2241668701 (55.1302080154s)\n",
      "48000 / 55379 : 64.6117019653 (59.156386137s)\n",
      "49000 / 55379 : 64.7931365967 (66.2823200226s)\n",
      "50000 / 55379 : 65.1498718262 (74.8110539913s)\n",
      "51000 / 55379 : 64.9938201904 (66.1487009525s)\n",
      "52000 / 55379 : 64.7444992065 (66.1525609493s)\n",
      "53000 / 55379 : 66.5032119751 (68.6603040695s)\n",
      "54000 / 55379 : 63.4912834167 (59.1151340008s)\n",
      "55000 / 55379 : 64.5628967285 (72.8198330402s)\n",
      "Error on val index 0: too many indices for array\n",
      "Error on val index 100: too many indices for array\n",
      "Error on val index 200: too many indices for array\n",
      "Error on val index 300: too many indices for array\n",
      "Error on val index 400: too many indices for array\n",
      "Error on val index 500: too many indices for array\n",
      "Error on val index 600: too many indices for array\n",
      "Error on val index 700: too many indices for array\n",
      "Error on val index 800: too many indices for array\n",
      "Error on val index 900: too many indices for array\n",
      "Error on val index 1000: too many indices for array\n",
      "Error on val index 1100: too many indices for array\n",
      "Error on val index 1200: too many indices for array\n",
      "Error on val index 1300: too many indices for array\n",
      "Error on val index 1400: too many indices for array\n",
      "Error on val index 1500: too many indices for array\n",
      "Error on val index 1600: too many indices for array\n",
      "Error on val index 1700: too many indices for array\n",
      "Error on val index 1800: too many indices for array\n",
      "Error on val index 1900: too many indices for array\n",
      "Error on val index 2000: too many indices for array\n",
      "Error on val index 2100: too many indices for array\n",
      "Error on val index 2200: too many indices for array\n",
      "Error on val index 2300: too many indices for array\n",
      "Error on val index 2400: too many indices for array\n",
      "Error on val index 2500: too many indices for array\n",
      "Error on val index 2600: too many indices for array\n",
      "Error on val index 2700: too many indices for array\n",
      "Error on val index 2800: too many indices for array\n",
      "Error on val index 2900: too many indices for array\n",
      "Error on val index 3000: too many indices for array\n",
      "Error on val index 3100: too many indices for array\n",
      "Error on val index 3200: too many indices for array\n",
      "Error on val index 3300: too many indices for array\n",
      "Error on val index 3400: too many indices for array\n",
      "Error on val index 3500: too many indices for array\n",
      "Error on val index 3600: too many indices for array\n",
      "Error on val index 3700: too many indices for array\n",
      "Error on val index 3800: too many indices for array\n",
      "Error on val index 3900: too many indices for array\n",
      "Error on val index 4000: too many indices for array\n",
      "Error on val index 4100: too many indices for array\n",
      "Error on val index 4200: too many indices for array\n",
      "Error on val index 4300: too many indices for array\n",
      "Error on val index 4400: too many indices for array\n",
      "Error on val index 4500: too many indices for array\n",
      "Error on val index 4600: too many indices for array\n",
      "Error on val index 4700: too many indices for array\n",
      "Error on val index 4800: too many indices for array\n",
      "Error on val index 4900: too many indices for array\n",
      "Error on val index 5000: too many indices for array\n",
      "Error on val index 5100: too many indices for array\n",
      "Error on val index 5200: too many indices for array\n",
      "Error on val index 5300: too many indices for array\n",
      "Error on val index 5400: too many indices for array\n",
      "Error on val index 5500: too many indices for array\n",
      "Error on val index 5600: too many indices for array\n",
      "Error on val index 5700: too many indices for array\n",
      "Error on val index 5800: too many indices for array\n",
      "Error on val index 5900: too many indices for array\n",
      "Epoch completed in 3780.00516987 seconds\n",
      "Train Acc: 0.0818721898192 Val Acc: 0.0 Val Loss: 0\n",
      "Epoch 2 / 4\n",
      "0 / 55379 : 6.69112205505 (2.10100698471s)\n",
      "1000 / 55379 : 64.106262207 (63.1125590801s)\n",
      "2000 / 55379 : 61.3014907837 (68.4349021912s)\n",
      "3000 / 55379 : 64.874458313 (62.1184270382s)\n",
      "4000 / 55379 : 62.35679245 (57.2985720634s)\n",
      "5000 / 55379 : 59.6516494751 (66.1499300003s)\n",
      "6000 / 55379 : 62.2084197998 (71.7897708416s)\n",
      "7000 / 55379 : 61.2671661377 (74.1995990276s)\n",
      "8000 / 55379 : 60.6467475891 (70.9723010063s)\n",
      "9000 / 55379 : 63.5206375122 (67.7518730164s)\n",
      "10000 / 55379 : 61.1287231445 (77.9578411579s)\n",
      "11000 / 55379 : 62.8142471313 (80.4315550327s)\n",
      "12000 / 55379 : 60.4413757324 (62.7362699509s)\n",
      "13000 / 55379 : 60.7164459229 (58.4178309441s)\n",
      "14000 / 55379 : 62.0475959778 (67.7495779991s)\n",
      "15000 / 55379 : 58.8207321167 (65.5657501221s)\n",
      "16000 / 55379 : 59.6284942627 (57.4332070351s)\n",
      "17000 / 55379 : 59.0828285217 (77.2126049995s)\n",
      "18000 / 55379 : 59.3540878296 (59.00583601s)\n",
      "19000 / 55379 : 60.2056045532 (59.7511310577s)\n",
      "20000 / 55379 : 61.526725769 (71.2578630447s)\n",
      "21000 / 55379 : 59.1866035461 (65.7997279167s)\n",
      "22000 / 55379 : 58.8769989014 (63.1565079689s)\n",
      "23000 / 55379 : 59.536403656 (66.0674948692s)\n",
      "24000 / 55379 : 61.2151679993 (58.9113781452s)\n",
      "25000 / 55379 : 57.9398498535 (70.9996161461s)\n",
      "26000 / 55379 : 59.141002655 (71.8148078918s)\n",
      "27000 / 55379 : 58.3866882324 (62.8933501244s)\n",
      "28000 / 55379 : 56.7361679077 (70.8975331783s)\n",
      "29000 / 55379 : 56.753162384 (57.1033420563s)\n",
      "30000 / 55379 : 56.7865715027 (73.7021560669s)\n",
      "31000 / 55379 : 55.7058753967 (67.8005378246s)\n",
      "32000 / 55379 : 58.5939598083 (70.3174610138s)\n",
      "33000 / 55379 : 54.8521766663 (80.0459930897s)\n",
      "34000 / 55379 : 56.7386169434 (58.2381210327s)\n",
      "35000 / 55379 : 56.5375061035 (70.4652509689s)\n",
      "36000 / 55379 : 57.9482955933 (75.3601589203s)\n",
      "37000 / 55379 : 55.1186828613 (61.2275230885s)\n",
      "38000 / 55379 : 56.6768569946 (61.3935678005s)\n",
      "39000 / 55379 : 56.3938789368 (65.9840788841s)\n",
      "40000 / 55379 : 57.5374145508 (75.1711070538s)\n",
      "41000 / 55379 : 57.4185256958 (63.7649261951s)\n",
      "42000 / 55379 : 56.2121315002 (58.2650809288s)\n",
      "43000 / 55379 : 55.8794784546 (73.1192531586s)\n",
      "44000 / 55379 : 54.7184677124 (60.0551660061s)\n",
      "45000 / 55379 : 55.0927810669 (68.9262471199s)\n",
      "46000 / 55379 : 54.9642906189 (64.7291929722s)\n",
      "47000 / 55379 : 55.4290046692 (53.9725410938s)\n",
      "48000 / 55379 : 53.4785461426 (59.0683438778s)\n",
      "49000 / 55379 : 54.986000061 (64.6630101204s)\n",
      "50000 / 55379 : 54.4854202271 (70.6312179565s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000 / 55379 : 53.9957771301 (63.4281640053s)\n",
      "52000 / 55379 : 53.0445861816 (63.1848270893s)\n",
      "53000 / 55379 : 55.7692489624 (66.3172419071s)\n",
      "54000 / 55379 : 53.2635993958 (57.858962059s)\n",
      "55000 / 55379 : 54.8640098572 (69.6226081848s)\n",
      "Error on val index 0: too many indices for array\n",
      "Error on val index 100: too many indices for array\n",
      "Error on val index 200: too many indices for array\n",
      "Error on val index 300: too many indices for array\n",
      "Error on val index 400: too many indices for array\n",
      "Error on val index 500: too many indices for array\n",
      "Error on val index 600: too many indices for array\n",
      "Error on val index 700: too many indices for array\n",
      "Error on val index 800: too many indices for array\n",
      "Error on val index 900: too many indices for array\n",
      "Error on val index 1000: too many indices for array\n",
      "Error on val index 1100: too many indices for array\n",
      "Error on val index 1200: too many indices for array\n",
      "Error on val index 1300: too many indices for array\n",
      "Error on val index 1400: too many indices for array\n",
      "Error on val index 1500: too many indices for array\n",
      "Error on val index 1600: too many indices for array\n",
      "Error on val index 1700: too many indices for array\n",
      "Error on val index 1800: too many indices for array\n",
      "Error on val index 1900: too many indices for array\n",
      "Error on val index 2000: too many indices for array\n",
      "Error on val index 2100: too many indices for array\n",
      "Error on val index 2200: too many indices for array\n",
      "Error on val index 2300: too many indices for array\n",
      "Error on val index 2400: too many indices for array\n",
      "Error on val index 2500: too many indices for array\n",
      "Error on val index 2600: too many indices for array\n",
      "Error on val index 2700: too many indices for array\n",
      "Error on val index 2800: too many indices for array\n",
      "Error on val index 2900: too many indices for array\n",
      "Error on val index 3000: too many indices for array\n",
      "Error on val index 3100: too many indices for array\n",
      "Error on val index 3200: too many indices for array\n",
      "Error on val index 3300: too many indices for array\n",
      "Error on val index 3400: too many indices for array\n",
      "Error on val index 3500: too many indices for array\n",
      "Error on val index 3600: too many indices for array\n",
      "Error on val index 3700: too many indices for array\n",
      "Error on val index 3800: too many indices for array\n",
      "Error on val index 3900: too many indices for array\n",
      "Error on val index 4000: too many indices for array\n",
      "Error on val index 4100: too many indices for array\n",
      "Error on val index 4200: too many indices for array\n",
      "Error on val index 4300: too many indices for array\n",
      "Error on val index 4400: too many indices for array\n",
      "Error on val index 4500: too many indices for array\n",
      "Error on val index 4600: too many indices for array\n",
      "Error on val index 4700: too many indices for array\n",
      "Error on val index 4800: too many indices for array\n",
      "Error on val index 4900: too many indices for array\n",
      "Error on val index 5000: too many indices for array\n",
      "Error on val index 5100: too many indices for array\n",
      "Error on val index 5200: too many indices for array\n",
      "Error on val index 5300: too many indices for array\n",
      "Error on val index 5400: too many indices for array\n",
      "Error on val index 5500: too many indices for array\n",
      "Error on val index 5600: too many indices for array\n",
      "Error on val index 5700: too many indices for array\n",
      "Error on val index 5800: too many indices for array\n",
      "Error on val index 5900: too many indices for array\n",
      "Epoch completed in 3760.767905 seconds\n",
      "Train Acc: 0.170533956915 Val Acc: 0.0 Val Loss: 0\n",
      "Epoch 3 / 4\n",
      "0 / 55379 : 5.78015232086 (1.95304894447s)\n",
      "1000 / 55379 : 53.6366615295 (62.6231868267s)\n",
      "2000 / 55379 : 50.8441772461 (63.7089059353s)\n",
      "3000 / 55379 : 53.8438110352 (60.5463829041s)\n",
      "4000 / 55379 : 52.4302177429 (55.8671720028s)\n",
      "5000 / 55379 : 49.7591056824 (65.2530798912s)\n",
      "6000 / 55379 : 51.9267654419 (69.8447749615s)\n",
      "7000 / 55379 : 51.9018554688 (72.37520504s)\n",
      "8000 / 55379 : 51.8896903992 (68.6226129532s)\n",
      "9000 / 55379 : 53.4060440063 (64.7226250172s)\n",
      "10000 / 55379 : 51.951084137 (75.7063031197s)\n",
      "11000 / 55379 : 54.0944786072 (77.5335948467s)\n",
      "12000 / 55379 : 50.9363937378 (63.2444429398s)\n",
      "13000 / 55379 : 51.0930328369 (56.8642168045s)\n",
      "14000 / 55379 : 53.1638641357 (67.1507709026s)\n",
      "15000 / 55379 : 50.0837783813 (64.6412038803s)\n",
      "16000 / 55379 : 50.477848053 (55.2974419594s)\n",
      "17000 / 55379 : 49.7296791077 (73.5354180336s)\n",
      "18000 / 55379 : 51.2275924683 (57.1855039597s)\n",
      "19000 / 55379 : 51.0156517029 (59.1054821014s)\n",
      "20000 / 55379 : 54.1716842651 (69.3254899979s)\n",
      "21000 / 55379 : 49.6638145447 (63.6664640903s)\n",
      "22000 / 55379 : 50.0503387451 (60.4439711571s)\n",
      "23000 / 55379 : 50.6753120422 (63.5111820698s)\n",
      "24000 / 55379 : 53.3175239563 (56.4444019794s)\n",
      "25000 / 55379 : 49.2432403564 (68.5671870708s)\n",
      "26000 / 55379 : 51.4220848083 (69.6346669197s)\n",
      "27000 / 55379 : 50.2564239502 (62.4097108841s)\n",
      "28000 / 55379 : 48.5511245728 (68.4617621899s)\n",
      "29000 / 55379 : 48.555847168 (54.978374958s)\n",
      "30000 / 55379 : 48.2518043518 (70.8500909805s)\n",
      "31000 / 55379 : 47.0322990417 (67.4274389744s)\n",
      "32000 / 55379 : 50.6442108154 (70.463602066s)\n",
      "33000 / 55379 : 46.2893104553 (78.0697479248s)\n",
      "34000 / 55379 : 47.7463989258 (59.1201341152s)\n",
      "35000 / 55379 : 47.9725341797 (69.4413928986s)\n",
      "36000 / 55379 : 49.6693725586 (72.6280391216s)\n",
      "37000 / 55379 : 46.7328910828 (58.860585928s)\n",
      "38000 / 55379 : 48.0618286133 (59.8380219936s)\n",
      "39000 / 55379 : 48.4081344604 (63.9628691673s)\n",
      "40000 / 55379 : 49.4195632935 (73.7738218307s)\n",
      "41000 / 55379 : 49.3031311035 (60.4630908966s)\n",
      "42000 / 55379 : 48.1983909607 (55.1366829872s)\n",
      "43000 / 55379 : 48.1587181091 (71.457901001s)\n",
      "44000 / 55379 : 47.3767776489 (59.2779638767s)\n",
      "45000 / 55379 : 47.7497787476 (68.9196610451s)\n",
      "46000 / 55379 : 48.1864891052 (64.1901700497s)\n",
      "47000 / 55379 : 47.4607124329 (53.3386628628s)\n",
      "48000 / 55379 : 45.6161880493 (59.1215040684s)\n",
      "49000 / 55379 : 47.8100090027 (65.6865830421s)\n",
      "50000 / 55379 : 47.1258163452 (71.2531020641s)\n",
      "51000 / 55379 : 46.479019165 (65.168941021s)\n",
      "52000 / 55379 : 45.2996139526 (62.9035840034s)\n",
      "53000 / 55379 : 47.8097000122 (67.5802140236s)\n",
      "54000 / 55379 : 45.816822052 (58.3576419353s)\n",
      "55000 / 55379 : 47.947517395 (68.9868500233s)\n",
      "Error on val index 0: too many indices for array\n",
      "Error on val index 100: too many indices for array\n",
      "Error on val index 200: too many indices for array\n",
      "Error on val index 300: too many indices for array\n",
      "Error on val index 400: too many indices for array\n",
      "Error on val index 500: too many indices for array\n",
      "Error on val index 600: too many indices for array\n",
      "Error on val index 700: too many indices for array\n",
      "Error on val index 800: too many indices for array\n",
      "Error on val index 900: too many indices for array\n",
      "Error on val index 1000: too many indices for array\n",
      "Error on val index 1100: too many indices for array\n",
      "Error on val index 1200: too many indices for array\n",
      "Error on val index 1300: too many indices for array\n",
      "Error on val index 1400: too many indices for array\n",
      "Error on val index 1500: too many indices for array\n",
      "Error on val index 1600: too many indices for array\n",
      "Error on val index 1700: too many indices for array\n",
      "Error on val index 1800: too many indices for array\n",
      "Error on val index 1900: too many indices for array\n",
      "Error on val index 2000: too many indices for array\n",
      "Error on val index 2100: too many indices for array\n",
      "Error on val index 2200: too many indices for array\n",
      "Error on val index 2300: too many indices for array\n",
      "Error on val index 2400: too many indices for array\n",
      "Error on val index 2500: too many indices for array\n",
      "Error on val index 2600: too many indices for array\n",
      "Error on val index 2700: too many indices for array\n",
      "Error on val index 2800: too many indices for array\n",
      "Error on val index 2900: too many indices for array\n",
      "Error on val index 3000: too many indices for array\n",
      "Error on val index 3100: too many indices for array\n",
      "Error on val index 3200: too many indices for array\n",
      "Error on val index 3300: too many indices for array\n",
      "Error on val index 3400: too many indices for array\n",
      "Error on val index 3500: too many indices for array\n",
      "Error on val index 3600: too many indices for array\n",
      "Error on val index 3700: too many indices for array\n",
      "Error on val index 3800: too many indices for array\n",
      "Error on val index 3900: too many indices for array\n",
      "Error on val index 4000: too many indices for array\n",
      "Error on val index 4100: too many indices for array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on val index 4200: too many indices for array\n",
      "Error on val index 4300: too many indices for array\n",
      "Error on val index 4400: too many indices for array\n",
      "Error on val index 4500: too many indices for array\n",
      "Error on val index 4600: too many indices for array\n",
      "Error on val index 4700: too many indices for array\n",
      "Error on val index 4800: too many indices for array\n",
      "Error on val index 4900: too many indices for array\n",
      "Error on val index 5000: too many indices for array\n",
      "Error on val index 5100: too many indices for array\n",
      "Error on val index 5200: too many indices for array\n",
      "Error on val index 5300: too many indices for array\n",
      "Error on val index 5400: too many indices for array\n",
      "Error on val index 5500: too many indices for array\n",
      "Error on val index 5600: too many indices for array\n",
      "Error on val index 5700: too many indices for array\n",
      "Error on val index 5800: too many indices for array\n",
      "Error on val index 5900: too many indices for array\n",
      "Epoch completed in 3683.89929891 seconds\n",
      "Train Acc: 0.235540547861 Val Acc: 0.0 Val Loss: 0\n",
      "Epoch 4 / 4\n",
      "0 / 55379 : 5.2329044342 (1.92817902565s)\n",
      "1000 / 55379 : 45.6002540588 (61.028096199s)\n",
      "2000 / 55379 : 42.9236984253 (63.3525688648s)\n",
      "3000 / 55379 : 46.4235305786 (60.5726678371s)\n",
      "4000 / 55379 : 44.8162574768 (55.1235320568s)\n",
      "5000 / 55379 : 42.7100906372 (63.8491389751s)\n",
      "6000 / 55379 : 44.5269126892 (68.8319540024s)\n",
      "7000 / 55379 : 44.5886917114 (72.0753958225s)\n",
      "8000 / 55379 : 44.6605987549 (68.6373090744s)\n",
      "9000 / 55379 : 45.2918510437 (63.7019319534s)\n",
      "10000 / 55379 : 44.5483283997 (74.2296600342s)\n",
      "11000 / 55379 : 46.8424987793 (76.269192934s)\n",
      "12000 / 55379 : 43.5900382996 (62.5526139736s)\n",
      "13000 / 55379 : 43.9011154175 (56.7500600815s)\n",
      "14000 / 55379 : 45.6732254028 (66.3296780586s)\n",
      "15000 / 55379 : 42.7904205322 (63.4656391144s)\n",
      "16000 / 55379 : 43.5234642029 (58.6251218319s)\n",
      "17000 / 55379 : 41.5234680176 (75.7746930122s)\n",
      "18000 / 55379 : 44.61378479 (59.9933888912s)\n",
      "19000 / 55379 : 43.3434829712 (58.6984670162s)\n",
      "20000 / 55379 : 47.9255752563 (70.0730872154s)\n",
      "21000 / 55379 : 41.8039207458 (63.9410920143s)\n",
      "22000 / 55379 : 43.1927719116 (60.5285060406s)\n",
      "23000 / 55379 : 43.2945671082 (62.9316720963s)\n",
      "24000 / 55379 : 45.9380340576 (57.1464650631s)\n",
      "25000 / 55379 : 41.7638893127 (70.3163251877s)\n",
      "26000 / 55379 : 44.3509368896 (69.7388370037s)\n",
      "27000 / 55379 : 44.1901321411 (63.4403560162s)\n",
      "28000 / 55379 : 41.0861473083 (68.5327649117s)\n",
      "29000 / 55379 : 41.7750587463 (56.0419170856s)\n",
      "30000 / 55379 : 41.5497703552 (69.1893570423s)\n",
      "31000 / 55379 : 40.1053390503 (66.4133439064s)\n",
      "32000 / 55379 : 42.9965438843 (68.4926080704s)\n",
      "33000 / 55379 : 39.0177574158 (80.294574976s)\n",
      "34000 / 55379 : 39.3830909729 (57.1795120239s)\n",
      "35000 / 55379 : 40.7613105774 (69.4060471058s)\n",
      "36000 / 55379 : 42.2997894287 (74.6846039295s)\n",
      "37000 / 55379 : 39.1690826416 (59.0535309315s)\n",
      "38000 / 55379 : 40.9356269836 (59.5921928883s)\n",
      "39000 / 55379 : 41.9697761536 (63.6180479527s)\n",
      "40000 / 55379 : 42.5670127869 (73.3784439564s)\n",
      "41000 / 55379 : 42.3578567505 (61.0451219082s)\n",
      "42000 / 55379 : 41.6158714294 (56.0744771957s)\n",
      "43000 / 55379 : 40.6898803711 (70.8416390419s)\n",
      "44000 / 55379 : 41.2131004333 (60.2476408482s)\n",
      "45000 / 55379 : 41.442565918 (68.2252810001s)\n",
      "46000 / 55379 : 41.9070358276 (62.9589309692s)\n",
      "47000 / 55379 : 40.1731033325 (53.6335151196s)\n",
      "48000 / 55379 : 37.2596702576 (59.4762248993s)\n",
      "49000 / 55379 : 40.3433876038 (67.0134840012s)\n",
      "50000 / 55379 : 41.1836624146 (71.2155640125s)\n",
      "51000 / 55379 : 39.5728302002 (63.5382931232s)\n",
      "52000 / 55379 : 38.2381362915 (63.2298388481s)\n",
      "53000 / 55379 : 40.2163543701 (66.1271569729s)\n",
      "54000 / 55379 : 38.7109603882 (58.3080320358s)\n",
      "55000 / 55379 : 40.8709335327 (68.0467410088s)\n",
      "Error on val index 0: too many indices for array\n",
      "Error on val index 100: too many indices for array\n",
      "Error on val index 200: too many indices for array\n",
      "Error on val index 300: too many indices for array\n",
      "Error on val index 400: too many indices for array\n",
      "Error on val index 500: too many indices for array\n",
      "Error on val index 600: too many indices for array\n",
      "Error on val index 700: too many indices for array\n",
      "Error on val index 800: too many indices for array\n",
      "Error on val index 900: too many indices for array\n",
      "Error on val index 1000: too many indices for array\n",
      "Error on val index 1100: too many indices for array\n",
      "Error on val index 1200: too many indices for array\n",
      "Error on val index 1300: too many indices for array\n",
      "Error on val index 1400: too many indices for array\n",
      "Error on val index 1500: too many indices for array\n",
      "Error on val index 1600: too many indices for array\n",
      "Error on val index 1700: too many indices for array\n",
      "Error on val index 1800: too many indices for array\n",
      "Error on val index 1900: too many indices for array\n",
      "Error on val index 2000: too many indices for array\n",
      "Error on val index 2100: too many indices for array\n",
      "Error on val index 2200: too many indices for array\n",
      "Error on val index 2300: too many indices for array\n",
      "Error on val index 2400: too many indices for array\n",
      "Error on val index 2500: too many indices for array\n",
      "Error on val index 2600: too many indices for array\n",
      "Error on val index 2700: too many indices for array\n",
      "Error on val index 2800: too many indices for array\n",
      "Error on val index 2900: too many indices for array\n",
      "Error on val index 3000: too many indices for array\n",
      "Error on val index 3100: too many indices for array\n",
      "Error on val index 3200: too many indices for array\n",
      "Error on val index 3300: too many indices for array\n",
      "Error on val index 3400: too many indices for array\n",
      "Error on val index 3500: too many indices for array\n",
      "Error on val index 3600: too many indices for array\n",
      "Error on val index 3700: too many indices for array\n",
      "Error on val index 3800: too many indices for array\n",
      "Error on val index 3900: too many indices for array\n",
      "Error on val index 4000: too many indices for array\n",
      "Error on val index 4100: too many indices for array\n",
      "Error on val index 4200: too many indices for array\n",
      "Error on val index 4300: too many indices for array\n",
      "Error on val index 4400: too many indices for array\n",
      "Error on val index 4500: too many indices for array\n",
      "Error on val index 4600: too many indices for array\n",
      "Error on val index 4700: too many indices for array\n",
      "Error on val index 4800: too many indices for array\n",
      "Error on val index 4900: too many indices for array\n",
      "Error on val index 5000: too many indices for array\n",
      "Error on val index 5100: too many indices for array\n",
      "Error on val index 5200: too many indices for array\n",
      "Error on val index 5300: too many indices for array\n",
      "Error on val index 5400: too many indices for array\n",
      "Error on val index 5500: too many indices for array\n",
      "Error on val index 5600: too many indices for array\n",
      "Error on val index 5700: too many indices for array\n",
      "Error on val index 5800: too many indices for array\n",
      "Error on val index 5900: too many indices for array\n",
      "Epoch completed in 3680.13836408 seconds\n",
      "Train Acc: 0.297134292782 Val Acc: 0.0 Val Loss: 0\n"
     ]
    }
   ],
   "source": [
    "train_model(model, opt, 0, 4, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_npz('gpu.model', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ids = []\n",
    "    ctxStrs = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ids.append(s)\n",
    "        ctxStrs.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "\n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           ids, \\\n",
    "           ctxStrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 36790 (1.46708202362s)\n",
      "1000 / 36790 (15.960078001s)\n",
      "2000 / 36790 (14.4043400288s)\n",
      "3000 / 36790 (16.1812560558s)\n",
      "4000 / 36790 (14.1495440006s)\n",
      "5000 / 36790 (14.5665690899s)\n",
      "6000 / 36790 (14.7809658051s)\n",
      "7000 / 36790 (13.1575860977s)\n",
      "8000 / 36790 (13.3060460091s)\n",
      "9000 / 36790 (12.8263981342s)\n",
      "10000 / 36790 (14.7221159935s)\n",
      "11000 / 36790 (14.0023782253s)\n",
      "12000 / 36790 (16.8604121208s)\n",
      "13000 / 36790 (13.507242918s)\n",
      "14000 / 36790 (14.7889289856s)\n",
      "15000 / 36790 (14.2691369057s)\n",
      "16000 / 36790 (16.0853450298s)\n",
      "17000 / 36790 (12.0515048504s)\n",
      "18000 / 36790 (14.905798912s)\n",
      "19000 / 36790 (17.0141391754s)\n",
      "20000 / 36790 (13.6597030163s)\n",
      "21000 / 36790 (17.3966171741s)\n",
      "22000 / 36790 (13.8897619247s)\n",
      "23000 / 36790 (12.1557569504s)\n",
      "24000 / 36790 (13.389934063s)\n",
      "25000 / 36790 (15.1089439392s)\n",
      "26000 / 36790 (13.1155648232s)\n",
      "27000 / 36790 (15.6933238506s)\n",
      "28000 / 36790 (14.4087979794s)\n",
      "29000 / 36790 (13.942948103s)\n",
      "30000 / 36790 (20.9394800663s)\n",
      "31000 / 36790 (13.57427001s)\n",
      "32000 / 36790 (15.3324551582s)\n",
      "33000 / 36790 (14.0243008137s)\n",
      "34000 / 36790 (14.8138279915s)\n",
      "35000 / 36790 (13.6387319565s)\n",
      "36000 / 36790 (12.2868440151s)\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "test_print_interval = 1000\n",
    "\n",
    "f = open('pred.csv', 'wb')\n",
    "out = csv.writer(f)\n",
    "out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i in range(0, len(test), test_batch_size):\n",
    "    ctx, qn, qnId, ctxStr = get_test_batch(i, test_batch_size, test)\n",
    "    model.reset_state()\n",
    "    start, end = model(ctx, qn)\n",
    "\n",
    "    for j in range(len(qnId)):\n",
    "        contextTokens = word_tokenize(ctxStr[j])\n",
    "\n",
    "        s = F.argmax(start[j]).data\n",
    "        e = F.argmax(end[j]).data\n",
    "        \n",
    "        s = min(s, len(contextTokens)-1)\n",
    "        e = max(e, s)\n",
    "        e = min(e, len(contextTokens)-1)        \n",
    "        \n",
    "        ans = \"\"\n",
    "        for k in range(s, e + 1):\n",
    "            ans += contextTokens[k] + \" \"\n",
    "        \n",
    "        out.writerow([qnId[j], normalize_answer(ans).encode('utf-8')])\n",
    "    \n",
    "    if i % test_print_interval == 0:\n",
    "        print i, \"/\", len(test), \"(\" + str(time.time() - startTime) + \"s)\"\n",
    "        startTime = time.time()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
