{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers, serializers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 50\n",
    "H_SIZE = 35\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    textVec = np.array([])\n",
    "    for tok in tokens:\n",
    "        textVec = np.append(textVec, glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return textVec.reshape(1, -1)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61379\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        ctxLen = len(paragraph['context'])\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'].lower())\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "            \n",
    "len_train = len(train)\n",
    "print len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7984\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']: \n",
    "        data = {}\n",
    "        data['context'] = paragraph['context']\n",
    "        data['contextVec'] = text2vec(paragraph['context'])\n",
    "        data['qna'] = []\n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qna = {}\n",
    "            qna['id'] = qnaJson['id']\n",
    "            qna['question'] = qnaJson['question']\n",
    "            qna['questionVec'] = text2vec(qnaJson['question'].lower())\n",
    "            data['qna'].append(qna)\n",
    "        test.append(data)\n",
    "len_test = len(test)\n",
    "print len_test               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(i, batch_size):\n",
    "    j = min(i + batch_size, len_train)\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = train[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ans_start.append(s)\n",
    "        ans_end.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(cmax, q.shape[1])\n",
    "        \n",
    "    cVec = np.zeros((batch_size, cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((batch_size, qmax), dtype=np.float32)        \n",
    "    for i in range(batch_size):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           Variable(np.array(ans_start, dtype=np.int32)).reshape(-1,1), \\\n",
    "           Variable(np.array(ans_end, dtype=np.int32)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "        \n",
    "    def get_para_rep(self, para, ru):\n",
    "        P = []\n",
    "        for i in range(0, para.shape[1], self.wordvec_size):\n",
    "            word = para[:, i:i+self.wordvec_size]\n",
    "            if self.use_gpu: \n",
    "                word.to_gpu()\n",
    "            P.append(ru(word))\n",
    "        return F.transpose(F.dstack(P), (0, 1, 2))\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        # context representation\n",
    "        Ds = self.get_para_rep(ctx, self.ctxRU)\n",
    "        \n",
    "        #question representation\n",
    "        Qs = self.get_para_rep(qn, self.qnRU)\n",
    "        \n",
    "        out_ins = []\n",
    "        for i in range(Ds.shape[0]):\n",
    "            D = Ds[i]\n",
    "            Q = Qs[i]\n",
    "            \n",
    "            #attention\n",
    "            affinity = F.matmul(D.T, Q)\n",
    "            A_Q = F.softmax(affinity)\n",
    "            A_D = F.softmax(affinity.T)\n",
    "\n",
    "            C_Q = F.matmul(D, A_Q)\n",
    "            C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "            \n",
    "            out_ins.append(F.concat((D, C_D), axis=0).T)\n",
    "        out_ins = F.transpose(F.dstack(out_ins), (0,2,1))\n",
    "\n",
    "        #output\n",
    "        h_fwd = []\n",
    "        for fout in out_ins:\n",
    "            h_fwd.append(self.outFwd(fout))\n",
    "        h_fwd = F.dstack(h_fwd)\n",
    "\n",
    "        h_bwd = []\n",
    "        for bout in out_ins[::-1]:\n",
    "            h_bwd.append(self.outBwd(bout))\n",
    "        h_bwd = F.dstack(h_bwd)\n",
    "        \n",
    "        u_in = F.transpose(F.concat((h_fwd, h_bwd)), (0,2,1))\n",
    "        U = self.outLinear(u_in.reshape(-1, 2*self.h_size))\n",
    "        return U.reshape(Ds.shape[0], -1, self.h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 35)\n"
     ]
    }
   ],
   "source": [
    "ctx, qn, ans_start, ans_end = get_batch(0, 5)\n",
    "\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Linear(2*h_size, h_size)\n",
    "            self.M2 = L.Linear(h_size, h_size)\n",
    "            self.M3 = L.Linear(2*h_size, 1)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        rs = []\n",
    "        for i in range(U.shape[0]):\n",
    "            rs.append(F.broadcast_to(r[i], U[i].shape))\n",
    "        r = F.transpose(F.dstack(rs), (2,0,1))\n",
    "        \n",
    "        m_in = F.concat((U, r), axis=2).reshape(-1, 2*self.h_size)\n",
    "        m1 = self.M1(m_in)\n",
    "        m2 = self.M2(m1)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3.reshape(U.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1)\n"
     ]
    }
   ],
   "source": [
    "highway = Highway(H_SIZE)\n",
    "\n",
    "h = Variable(np.zeros((5, H_SIZE), dtype=np.float32))\n",
    "us = U[:,0].reshape(5, -1)\n",
    "ue = U[:,-1].reshape(5, -1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = self.dec_state(F.concat((us,ue)))\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "        beta = self.HwayEnd(U, h, U[range(U.shape[0]), s], ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1) [[115 115 115 115 115]]\n",
      "(5, 125, 1) [[118 118 118 118 118]]\n"
     ]
    }
   ],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE)\n",
    "\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn): \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = np.zeros(U.shape[0], 'i')\n",
    "        end = np.zeros(U.shape[0], 'i') - 1        \n",
    "        for i in range(3):            \n",
    "            us = U[range(U.shape[0]), start]\n",
    "            ue = U[range(U.shape[0]), end]\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "            end = F.argmax(beta, axis=1).data.reshape(-1)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 125, 1) [[49 49 49 49 49]]\n",
      "(5, 125, 1) [[88 88 88 88 88]]\n"
     ]
    }
   ],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE)\n",
    "alpha, beta = model(ctx, qn)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(alpha=1e-3)\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, USE_GPU)\n",
    "if USE_GPU:\n",
    "    model.to_gpu()\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, opt, n_epoch, batch_size, print_interval):\n",
    "    for epoch in range(n_epoch):\n",
    "        print \"Epoch\", epoch + 1, \"/\", n_epoch\n",
    "        startTime = time.time()\n",
    "\n",
    "        opt.new_epoch()\n",
    "        \n",
    "        interval_loss = 0\n",
    "        interval_start = time.time()\n",
    "        for i in range(0, len_train, batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                loss = loss_start + loss_end\n",
    "\n",
    "                interval_loss += loss.data\n",
    "                if i % print_interval == 0:\n",
    "                    if i > 0:\n",
    "                        interval_loss = interval_loss / print_interval\n",
    "                    print i, \"/\", len_train, \":\", \\\n",
    "                          interval_loss, \\\n",
    "                          \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                    interval_loss = 0\n",
    "                    interval_start = time.time()\n",
    "\n",
    "                model.cleargrads()\n",
    "                loss.backward()\n",
    "\n",
    "                opt.update()\n",
    "            except IndexError as e:\n",
    "                print \"Error on index \" + str(i) + \":\", e\n",
    "        print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1\n",
      "0 / 61379 : 10.311882019 (0.886663913727s)\n",
      "1000 / 61379 : 0.198502500534 (67.8347129822s)\n",
      "2000 / 61379 : 0.192362913132 (66.8717541695s)\n",
      "3000 / 61379 : 0.185226672173 (72.4134180546s)\n",
      "4000 / 61379 : 0.175038178921 (72.4889211655s)\n",
      "5000 / 61379 : 0.172880963802 (72.0698149204s)\n",
      "6000 / 61379 : 0.17170497179 (67.4792408943s)\n",
      "7000 / 61379 : 0.167888775349 (77.6480519772s)\n",
      "8000 / 61379 : 0.182942715645 (86.5606799126s)\n",
      "9000 / 61379 : 0.175077447891 (69.5567691326s)\n",
      "10000 / 61379 : 0.177688225746 (79.4367339611s)\n",
      "11000 / 61379 : 0.165159847736 (78.6525480747s)\n",
      "12000 / 61379 : 0.180168470383 (124.09850812s)\n",
      "13000 / 61379 : 0.169676775932 (76.5532829762s)\n",
      "14000 / 61379 : 0.178552587509 (102.390233994s)\n",
      "15000 / 61379 : 0.171711821556 (85.7483830452s)\n",
      "16000 / 61379 : 0.165616703987 (89.6517059803s)\n",
      "17000 / 61379 : 0.168699715614 (139.526945114s)\n",
      "18000 / 61379 : 0.167678033352 (123.047897816s)\n",
      "19000 / 61379 : 0.165388251305 (89.5614140034s)\n",
      "20000 / 61379 : 0.166455740929 (100.851838827s)\n",
      "21000 / 61379 : 0.1582158494 (82.6645419598s)\n",
      "22000 / 61379 : 0.168779727936 (129.239773989s)\n",
      "23000 / 61379 : 0.160111708641 (90.1099879742s)\n",
      "24000 / 61379 : 0.168915283203 (81.6933369637s)\n",
      "25000 / 61379 : 0.169910485744 (90.8879189491s)\n",
      "26000 / 61379 : 0.165115471363 (81.3342339993s)\n",
      "27000 / 61379 : 0.161835966587 (117.180962086s)\n",
      "28000 / 61379 : 0.157265158653 (75.7757439613s)\n",
      "29000 / 61379 : 0.158809340477 (126.400300026s)\n",
      "30000 / 61379 : 0.162680273533 (121.475761175s)\n",
      "31000 / 61379 : 0.159528130054 (104.06753397s)\n",
      "32000 / 61379 : 0.154860574245 (99.5168530941s)\n",
      "33000 / 61379 : 0.13630393362 (67.1675291061s)\n",
      "34000 / 61379 : 0.155785181522 (84.3291170597s)\n",
      "35000 / 61379 : 0.157866099358 (132.814684153s)\n",
      "36000 / 61379 : 0.167034556389 (76.2927479744s)\n",
      "37000 / 61379 : 0.154244839668 (124.570737839s)\n",
      "38000 / 61379 : 0.163610910416 (119.701861858s)\n",
      "39000 / 61379 : 0.15650444603 (77.7149429321s)\n",
      "40000 / 61379 : 0.152665498734 (94.2317359447s)\n",
      "41000 / 61379 : 0.140331911564 (66.802888155s)\n",
      "42000 / 61379 : 0.151643128395 (93.0190820694s)\n",
      "43000 / 61379 : 0.150480444431 (71.6060819626s)\n",
      "44000 / 61379 : 0.153797213078 (74.8477339745s)\n",
      "45000 / 61379 : 0.150007139206 (74.7322227955s)\n",
      "46000 / 61379 : 0.160049989223 (82.5744068623s)\n",
      "47000 / 61379 : 0.152731919765 (76.3175499439s)\n",
      "48000 / 61379 : 0.152666595936 (74.4828500748s)\n",
      "49000 / 61379 : 0.143630163193 (54.1380989552s)\n",
      "50000 / 61379 : 0.141283189774 (61.5884270668s)\n",
      "51000 / 61379 : 0.144878854752 (59.9335570335s)\n",
      "52000 / 61379 : 0.152823672295 (71.6787800789s)\n",
      "53000 / 61379 : 0.155704269886 (77.0640590191s)\n",
      "54000 / 61379 : 0.131351455212 (81.623508215s)\n",
      "55000 / 61379 : 0.150625844955 (81.1875669956s)\n",
      "56000 / 61379 : 0.15085608387 (96.2414858341s)\n",
      "57000 / 61379 : 0.150856803894 (83.2322010994s)\n",
      "58000 / 61379 : 0.147774662971 (77.1699900627s)\n",
      "59000 / 61379 : 0.144880419731 (78.4613378048s)\n",
      "60000 / 61379 : 0.147389233589 (102.79101181s)\n",
      "61000 / 61379 : 0.152128216267 (99.9735338688s)\n",
      "Error on index 61350: list index out of range\n",
      "Epoch completed in 5386.73655486 seconds\n"
     ]
    }
   ],
   "source": [
    "train_model(model, opt, 1, 50, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serializers.save_npz('one_epoch.model', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_batch(i):    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    \n",
    "    testData = test[i]\n",
    "    for qna in testData['qna']:\n",
    "        ctx.append(testData['contextVec'])\n",
    "        qn.append(qna['questionVec'])\n",
    "        cmax = max(cmax, testData['contextVec'].shape[1])\n",
    "        qmax = max(cmax, qna['questionVec'].shape[1])\n",
    "    \n",
    "    batch_size = len(qn)\n",
    "    cVec = np.zeros((batch_size, cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((batch_size, qmax), dtype=np.float32)        \n",
    "    for i in range(batch_size):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), Variable(qVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('pred.csv', 'wb')\n",
    "out = csv.writer(f)\n",
    "out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "startTime = time.time()\n",
    "for idx, t in enumerate(test):\n",
    "    contextTokens = word_tokenize(t['context'])\n",
    "    \n",
    "    ctx, qn = get_test_batch(idx)\n",
    "    model.reset_state()\n",
    "    start, end = model(ctx, qn)\n",
    "    \n",
    "    for idx_qna, qna in enumerate(t['qna']):\n",
    "        id = qna['id']\n",
    "      \n",
    "        s = F.argmax(start[idx_qna]).data\n",
    "        e = F.argmax(end[idx_qna]).data\n",
    "        \n",
    "        s = min(s, len(contextTokens)-1)\n",
    "        e = max(e, s)\n",
    "        e = min(e, len(contextTokens)-1)        \n",
    "        \n",
    "        ans = \"\"\n",
    "        for i in range(s, e + 1):\n",
    "            ans += contextTokens[i] + \" \"\n",
    "        \n",
    "        out.writerow([id, normalize_answer(ans).encode('utf-8')])\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print idx, \"/\", len(test), \"(\" + str(time.time() - startTime) + \"s)\"\n",
    "        startTime = time.time()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
