{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv, json, string, re, time\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import chainer\n",
    "from chainer import Chain, Variable, Parameter\n",
    "from chainer import iterators, optimizers, serializers\n",
    "import chainer.initializers as I\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "WORD_VECTOR_SIZE = 300\n",
    "H_SIZE = 200\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = {}\n",
    "f = open('glove/glove.6B.' + str(WORD_VECTOR_SIZE) + 'd.txt', 'rb')\n",
    "reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONE)\n",
    "for row in reader:\n",
    "    key = row[0]\n",
    "    vector = map(float, row[1:])\n",
    "    glove[key] = np.array(vector, dtype=np.float32).reshape(1,-1)\n",
    "len(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    textVec = np.array([])\n",
    "    for tok in tokens:\n",
    "        textVec = np.append(textVec, glove.get(tok, np.zeros((1,WORD_VECTOR_SIZE), dtype=np.float32)))\n",
    "    return textVec.reshape(1, -1)\n",
    "\n",
    "def answerpos(context, answer, answer_start):\n",
    "    start = len(word_tokenize(context[:answer_start]))\n",
    "    ans_len = len(word_tokenize(answer))\n",
    "    \n",
    "    return start, start + ans_len - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61379"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "for jsonRow in json.loads(open('dataset/train.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnVec = text2vec(qnaJson['question'])\n",
    "            \n",
    "            ansStart, ansEnd = answerpos(paragraph['context'], \n",
    "                                           qnaJson['answer']['text'], \n",
    "                                           qnaJson['answer']['answer_start'])\n",
    "            \n",
    "            train.append((ctxVec, qnVec, ansStart, ansEnd))\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 55379\n"
     ]
    }
   ],
   "source": [
    "shuffle(train)\n",
    "val = train[:6000]\n",
    "train = train[6000:]\n",
    "\n",
    "print len(val), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36790"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for jsonRow in json.loads(open('dataset/test.json', 'rb').read()):\n",
    "    for paragraph in jsonRow['paragraphs']:\n",
    "        ctx = paragraph['context']\n",
    "        ctxVec = text2vec(paragraph['context'])\n",
    "        \n",
    "        for qnaJson in paragraph['qas']:\n",
    "            qnId = qnaJson['id']\n",
    "            qnVec = text2vec(qnaJson['question'])            \n",
    "            test.append((ctxVec, qnVec, qnId, ctx))\n",
    "  \n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ans_start = []\n",
    "    ans_end = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ans_start.append(s)\n",
    "        ans_end.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "        \n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           Variable(np.array(ans_start, dtype=np.int32)).reshape(-1,1), \\\n",
    "           Variable(np.array(ans_end, dtype=np.int32)).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 58200)\n",
      "(5, 5700)\n",
      "(5, 1)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "c, q, s, e = get_batch(0, 5, train)\n",
    "print c.shape\n",
    "print q.shape\n",
    "print s.shape\n",
    "print e.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network\n",
    "* RNN Tutorial: http://docs.chainer.org/en/stable/tutorial/recurrentnet.html\n",
    "* Training Tutorial: http://docs.chainer.org/en/stable/tutorial/train_loop.html\n",
    "* Attention: https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/\n",
    "* Pointer: http://fastml.com/introduction-to-pointer-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoattentionEncoder(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(CoattentionEncoder, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.wordvec_size = wordvec_size\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.ctxRU = L.LSTM(wordvec_size, h_size)\n",
    "\n",
    "            self.qnRU = L.LSTM(wordvec_size, h_size)\n",
    "            self.qnLinear = L.Linear(h_size, h_size)\n",
    "            \n",
    "            self.outFwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outBwd = L.LSTM(3*h_size, h_size)\n",
    "            self.outLinear = L.Linear(2*h_size, h_size)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"CodynamicAttention uses GPU\", self.use_gpu\n",
    "                self.ctxRU.to_gpu()\n",
    "                self.qnRU.to_gpu()\n",
    "                self.qnLinear.to_gpu()\n",
    "                self.outFwd.to_gpu()\n",
    "                self.outBwd.to_gpu()\n",
    "                self.outLinear.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.ctxRU.reset_state()\n",
    "        self.qnRU.reset_state()\n",
    "        self.outFwd.reset_state()\n",
    "        self.outBwd.reset_state()\n",
    "        \n",
    "    def get_para_rep(self, para, ru):\n",
    "        P = []\n",
    "        for i in range(0, para.shape[1], self.wordvec_size):\n",
    "            word = para[:, i:i+self.wordvec_size]\n",
    "            if self.use_gpu: \n",
    "                word.to_gpu()\n",
    "            P.append(ru(word))\n",
    "        return F.transpose(F.dstack(P), (0, 1, 2))\n",
    "            \n",
    "    def __call__(self, ctx, qn):\n",
    "        # context representation\n",
    "        Ds = self.get_para_rep(ctx, self.ctxRU)\n",
    "        \n",
    "        #question representation\n",
    "        Qs = self.get_para_rep(qn, self.qnRU)\n",
    "        \n",
    "        out_ins = []\n",
    "        for i in range(Ds.shape[0]):\n",
    "            D = Ds[i]\n",
    "            Q = Qs[i]\n",
    "            \n",
    "            #attention\n",
    "            affinity = F.matmul(D.T, Q)\n",
    "            A_Q = F.softmax(affinity)\n",
    "            A_D = F.softmax(affinity.T)\n",
    "\n",
    "            C_Q = F.matmul(D, A_Q)\n",
    "            C_D = F.matmul(F.concat((Q, C_Q), axis=0), A_D)\n",
    "            \n",
    "            out_ins.append(F.concat((D, C_D), axis=0).T)\n",
    "        out_ins = F.transpose(F.dstack(out_ins), (0,2,1))\n",
    "\n",
    "        #output\n",
    "        h_fwd = []\n",
    "        for fout in out_ins:\n",
    "            h_fwd.append(self.outFwd(fout))\n",
    "        h_fwd = F.dstack(h_fwd)\n",
    "\n",
    "        h_bwd = []\n",
    "        for bout in out_ins[::-1]:\n",
    "            h_bwd.append(self.outBwd(bout))\n",
    "        h_bwd = F.dstack(h_bwd)\n",
    "        \n",
    "        u_in = F.transpose(F.concat((h_fwd, h_bwd)), (0,2,1))\n",
    "        U = self.outLinear(u_in.reshape(-1, 2*self.h_size))\n",
    "        return U.reshape(Ds.shape[0], -1, self.h_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 194, 200)\n"
     ]
    }
   ],
   "source": [
    "ctx, qn, ans_start, ans_end = get_batch(0, 5, train)\n",
    "\n",
    "encoder = CoattentionEncoder(WORD_VECTOR_SIZE, H_SIZE)\n",
    "\n",
    "U = encoder(ctx, qn)\n",
    "print U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(Highway, self).__init__()\n",
    "        \n",
    "        self.h_size = h_size\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.MLP = L.Linear(3*h_size, h_size, nobias=True)\n",
    "            self.M1 = L.Linear(2*h_size, h_size)\n",
    "            self.M2 = L.Linear(h_size, h_size)\n",
    "            self.M3 = L.Linear(2*h_size, 1)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"Highway uses GPU\", self.use_gpu\n",
    "                self.MLP.to_gpu()\n",
    "                self.M1.to_gpu()\n",
    "                self.M2.to_gpu()\n",
    "                self.M3.to_gpu()\n",
    "            \n",
    "    def __call__(self, U, h, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            h.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        r = F.tanh(self.MLP(F.hstack([h, us, ue])))\n",
    "        rs = []\n",
    "        for i in range(U.shape[0]):\n",
    "            rs.append(F.broadcast_to(r[i], U[i].shape))\n",
    "        r = F.transpose(F.dstack(rs), (2,0,1))\n",
    "        \n",
    "        m_in = F.concat((U, r), axis=2).reshape(-1, 2*self.h_size)\n",
    "        m1 = self.M1(m_in)\n",
    "        m2 = self.M2(m1)\n",
    "        m3 = self.M3(F.concat((m1,m2)))\n",
    "        \n",
    "        return m3.reshape(U.shape[0], -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 194, 1)\n"
     ]
    }
   ],
   "source": [
    "highway = Highway(H_SIZE)\n",
    "\n",
    "h = Variable(np.zeros((5, H_SIZE), dtype=np.float32))\n",
    "us = U[:,0].reshape(5, -1)\n",
    "ue = U[:,-1].reshape(5, -1)\n",
    "\n",
    "alpha = highway(U, h, us, ue)\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPointingDecoder(Chain):\n",
    "    def __init__(self, h_size, use_gpu=False):\n",
    "        super(DynamicPointingDecoder, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.dec_state = L.LSTM(2*h_size, h_size)\n",
    "            self.HwayStart = Highway(h_size, use_gpu)\n",
    "            self.HwayEnd = Highway(h_size, use_gpu)\n",
    "            \n",
    "            if self.use_gpu:\n",
    "                print \"DynamicPointincDecoded uses GPU\", self.use_gpu\n",
    "                self.dec_state.to_gpu()\n",
    "                self.HwayStart.to_gpu()\n",
    "                self.HwayEnd.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.dec_state.reset_state()\n",
    "            \n",
    "    def __call__(self, U, us, ue):\n",
    "        if self.use_gpu:\n",
    "            U.to_gpu()\n",
    "            us.to_gpu()\n",
    "            ue.to_gpu()\n",
    "        \n",
    "        h = self.dec_state(F.concat((us,ue)))\n",
    "        alpha = self.HwayStart(U, h, us, ue)\n",
    "        s = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "        beta = self.HwayEnd(U, h, U[range(U.shape[0]), s], ue)\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 194, 1) [[148  88 128  98 138]]\n",
      "(5, 194, 1) [[192 149 164  71 142]]\n"
     ]
    }
   ],
   "source": [
    "decoder = DynamicPointingDecoder(H_SIZE)\n",
    "\n",
    "alpha, beta = decoder(U, us, ue)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadNet(Chain):\n",
    "    def __init__(self, wordvec_size, h_size, use_gpu=False):\n",
    "        super(SquadNet, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "                \n",
    "        with self.init_scope():\n",
    "            self.encoder = CoattentionEncoder(wordvec_size, h_size, use_gpu)\n",
    "            self.decoder = DynamicPointingDecoder(h_size, use_gpu)\n",
    "            \n",
    "            if use_gpu:\n",
    "                print \"SquadNet uses GPU\", self.use_gpu\n",
    "                self.encoder.to_gpu()\n",
    "                self.decoder.to_gpu()\n",
    "            \n",
    "    def reset_state(self):\n",
    "        self.encoder.reset_state()\n",
    "        self.decoder.reset_state()\n",
    "            \n",
    "    def __call__(self, ctx, qn): \n",
    "        U = self.encoder(ctx, qn)\n",
    "        \n",
    "        start = np.zeros(U.shape[0], 'i')\n",
    "        end = np.zeros(U.shape[0], 'i') - 1        \n",
    "        for i in range(3):            \n",
    "            us = U[range(U.shape[0]), start]\n",
    "            ue = U[range(U.shape[0]), end]\n",
    "            alpha, beta = self.decoder(U, us, ue)\n",
    "            \n",
    "            start = F.argmax(alpha, axis=1).data.reshape(-1)\n",
    "            end = F.argmax(beta, axis=1).data.reshape(-1)\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 194, 1) [[35  6 10  9 14]]\n",
      "(5, 194, 1) [[11 10  5  9 14]]\n"
     ]
    }
   ],
   "source": [
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE)\n",
    "alpha, beta = model(ctx, qn)\n",
    "print alpha.shape, F.argmax(alpha, axis=1).data.reshape(1,-1)\n",
    "print beta.shape, F.argmax(beta, axis=1).data.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodynamicAttention uses GPU True\n",
      "Highway uses GPU True\n",
      "Highway uses GPU True\n",
      "DynamicPointincDecoded uses GPU True\n",
      "SquadNet uses GPU True\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(alpha=1e-3)\n",
    "model = SquadNet(WORD_VECTOR_SIZE, H_SIZE, USE_GPU)\n",
    "if USE_GPU:\n",
    "    model.to_gpu()\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, epoch_start, epoch_end, batch_size, print_interval):\n",
    "    for epoch in range(epoch_start, epoch_end):\n",
    "        print \"Epoch\", epoch + 1, \"/\", epoch_end\n",
    "        startTime = time.time()\n",
    "        epochScore = 0\n",
    "\n",
    "        opt.new_epoch()\n",
    "        \n",
    "        interval_loss = 0\n",
    "        interval_start = time.time()\n",
    "        for i in range(0, len(train), batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size, train)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "                \n",
    "                pred_start = pred_start[:ctx.shape[0],:,:]\n",
    "                pred_end = pred_end[:ctx.shape[0]]\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                loss = loss_start + loss_end\n",
    "\n",
    "                interval_loss += loss.data\n",
    "                if i % print_interval == 0:\n",
    "                    print i, \"/\", len(train), \":\", \\\n",
    "                          interval_loss, \\\n",
    "                          \"(\" + str(time.time() - interval_start) + \"s)\"\n",
    "                    interval_loss = 0\n",
    "                    interval_start = time.time()\n",
    "                \n",
    "                s = F.argmax(pred_start, axis=1).data\n",
    "                e = F.argmax(pred_end, axis=1).data\n",
    "                for j in range(s.shape[0]):\n",
    "                    if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                        epochScore += 1\n",
    "\n",
    "                model.cleargrads()\n",
    "                loss.backward()\n",
    "\n",
    "                opt.update()\n",
    "            except IndexError as e:\n",
    "                print \"Error on train index \" + str(i) + \":\", e\n",
    "        \n",
    "        valLoss = 0\n",
    "        valScore = 0\n",
    "        for i in range(0, len(val), batch_size):\n",
    "            try:\n",
    "                ctx, qn, ans_start, ans_end = get_batch(i, batch_size, val)\n",
    "                if USE_GPU:\n",
    "                    ans_start.to_gpu()\n",
    "                    ans_end.to_gpu()\n",
    "\n",
    "                model.reset_state()\n",
    "                pred_start, pred_end = model(ctx, qn)\n",
    "\n",
    "                loss_start = F.softmax_cross_entropy(pred_start, ans_start)\n",
    "                loss_end = F.softmax_cross_entropy(pred_end, ans_end)\n",
    "                valLoss += (loss_start + loss_end).data\n",
    "                \n",
    "                s = F.argmax(pred_start, axis=1).data\n",
    "                e = F.argmax(pred_end, axis=1).data\n",
    "                for j in range(s.shape[0]):\n",
    "                    if s[j] == ans_start.data[j] and e[j] == ans_end.data[j]:\n",
    "                        valScore += 1\n",
    "            except IndexError as e:\n",
    "                print \"Error on val index \" + str(i) + \":\", e\n",
    "        \n",
    "        epochAcc = float(epochScore) / len(train)\n",
    "        valAcc = float(valScore) / len(val)\n",
    "        \n",
    "        serializers.save_npz('gpu-epoch' + str(epoch+1) + '.model', model)\n",
    "        print \"Epoch completed in\", time.time() - startTime, \"seconds\"\n",
    "        print \"Train Acc:\", epochAcc, \"Val Acc:\", valAcc, \"Val Loss:\", valLoss      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "0 / 55379 : 11.3935489655 (11.4475779533s)\n",
      "1000 / 55379 : 102.294250488 (58.5667181015s)\n",
      "2000 / 55379 : 97.2259674072 (58.26846385s)\n",
      "3000 / 55379 : 94.2286453247 (53.5731408596s)\n",
      "4000 / 55379 : 91.2600326538 (59.2188150883s)\n",
      "5000 / 55379 : 88.3196258545 (53.769302845s)\n",
      "6000 / 55379 : 87.3707122803 (63.6763970852s)\n",
      "7000 / 55379 : 87.5026092529 (73.0078141689s)\n",
      "8000 / 55379 : 86.7635650635 (58.9395349026s)\n",
      "9000 / 55379 : 85.8834533691 (70.6529350281s)\n",
      "10000 / 55379 : 83.75 (67.6852450371s)\n",
      "11000 / 55379 : 81.8541870117 (60.021132946s)\n",
      "12000 / 55379 : 80.5402832031 (53.6953790188s)\n",
      "13000 / 55379 : 79.8775177002 (62.4886689186s)\n",
      "14000 / 55379 : 78.3037567139 (50.0037460327s)\n",
      "15000 / 55379 : 77.7997894287 (60.335878849s)\n",
      "16000 / 55379 : 76.9636535645 (67.5340139866s)\n",
      "17000 / 55379 : 75.4434967041 (69.3194470406s)\n",
      "18000 / 55379 : 74.7404785156 (70.1353960037s)\n",
      "19000 / 55379 : 75.1091766357 (61.3619999886s)\n",
      "20000 / 55379 : 72.7371520996 (66.8651800156s)\n",
      "21000 / 55379 : 74.3105773926 (51.9347500801s)\n",
      "22000 / 55379 : 72.4702529907 (68.5165112019s)\n",
      "23000 / 55379 : 71.9582061768 (69.1999359131s)\n",
      "24000 / 55379 : 71.7452316284 (62.5468580723s)\n",
      "25000 / 55379 : 71.1470718384 (57.3349409103s)\n",
      "26000 / 55379 : 70.8270874023 (54.8867440224s)\n",
      "27000 / 55379 : 71.6455001831 (60.9004330635s)\n",
      "28000 / 55379 : 70.2904129028 (74.4526028633s)\n",
      "29000 / 55379 : 71.1169433594 (67.2976081371s)\n",
      "30000 / 55379 : 69.5669021606 (77.8741810322s)\n",
      "31000 / 55379 : 67.7298126221 (61.0442929268s)\n",
      "32000 / 55379 : 69.3546218872 (68.393558979s)\n",
      "33000 / 55379 : 68.2235870361 (55.8874740601s)\n",
      "34000 / 55379 : 69.2873535156 (92.9065980911s)\n",
      "35000 / 55379 : 67.7776641846 (57.744232893s)\n",
      "36000 / 55379 : 68.1702575684 (54.6528048515s)\n",
      "37000 / 55379 : 68.4565734863 (62.0900790691s)\n",
      "38000 / 55379 : 67.228225708 (56.5710730553s)\n",
      "39000 / 55379 : 66.670135498 (48.4446189404s)\n",
      "40000 / 55379 : 67.5314178467 (70.2539408207s)\n",
      "41000 / 55379 : 67.813079834 (66.6170578003s)\n",
      "42000 / 55379 : 68.5712738037 (69.0152850151s)\n",
      "43000 / 55379 : 67.2512435913 (66.8595991135s)\n",
      "44000 / 55379 : 65.7105941772 (68.1580960751s)\n",
      "45000 / 55379 : 66.9119949341 (78.3866071701s)\n",
      "46000 / 55379 : 67.116645813 (60.4683959484s)\n",
      "47000 / 55379 : 65.7408981323 (57.0320460796s)\n",
      "48000 / 55379 : 66.1601867676 (63.3495118618s)\n",
      "49000 / 55379 : 66.4646224976 (64.1196460724s)\n",
      "50000 / 55379 : 65.8338241577 (60.7589378357s)\n",
      "51000 / 55379 : 66.3545532227 (56.2162661552s)\n",
      "52000 / 55379 : 65.8697662354 (58.4019398689s)\n",
      "53000 / 55379 : 65.6424636841 (57.779763937s)\n",
      "54000 / 55379 : 64.4333114624 (66.5622310638s)\n",
      "55000 / 55379 : 63.373790741 (66.3518919945s)\n",
      "Epoch completed in 3601.93022203 seconds\n",
      "Train Acc: 0.07997616425 Val Acc: 0.1255 Val Loss: 389.248291016\n",
      "Epoch 2 / 10\n",
      "0 / 55379 : 6.09652519226 (1.32563090324s)\n",
      "1000 / 55379 : 65.2341766357 (56.3220391273s)\n",
      "2000 / 55379 : 65.9041824341 (57.2256710529s)\n",
      "3000 / 55379 : 63.6341362 (52.558371067s)\n",
      "4000 / 55379 : 64.5706100464 (58.8880369663s)\n",
      "5000 / 55379 : 62.1916275024 (54.1496219635s)\n",
      "6000 / 55379 : 61.5459289551 (63.6960608959s)\n",
      "7000 / 55379 : 63.7934188843 (73.3384971619s)\n",
      "8000 / 55379 : 62.7962913513 (58.7043278217s)\n",
      "9000 / 55379 : 64.0199356079 (72.2260689735s)\n",
      "10000 / 55379 : 63.0832901001 (68.4776349068s)\n",
      "11000 / 55379 : 61.8484268188 (59.5599122047s)\n",
      "12000 / 55379 : 62.0290756226 (53.4522738457s)\n",
      "13000 / 55379 : 61.9929924011 (63.8544719219s)\n",
      "14000 / 55379 : 60.2556762695 (51.9500160217s)\n",
      "15000 / 55379 : 61.5995826721 (61.168200016s)\n",
      "16000 / 55379 : 60.0822486877 (67.8403701782s)\n",
      "17000 / 55379 : 60.4314460754 (69.5172841549s)\n",
      "18000 / 55379 : 60.593875885 (68.9575359821s)\n",
      "19000 / 55379 : 60.1431808472 (59.8546550274s)\n",
      "20000 / 55379 : 59.2265892029 (66.5636930466s)\n",
      "21000 / 55379 : 61.1344070435 (51.3451340199s)\n",
      "22000 / 55379 : 57.8535652161 (68.949431181s)\n",
      "23000 / 55379 : 58.6305961609 (68.76375103s)\n",
      "24000 / 55379 : 59.3348579407 (60.8194520473s)\n",
      "25000 / 55379 : 58.0539665222 (58.3017199039s)\n",
      "26000 / 55379 : 58.0967941284 (56.246970892s)\n",
      "27000 / 55379 : 58.6917877197 (60.4419391155s)\n",
      "28000 / 55379 : 57.1778106689 (76.9402399063s)\n",
      "29000 / 55379 : 58.3126525879 (67.7240929604s)\n",
      "30000 / 55379 : 57.4050559998 (78.6051018238s)\n",
      "31000 / 55379 : 55.1198348999 (60.4782829285s)\n",
      "32000 / 55379 : 57.4411277771 (68.3186957836s)\n",
      "33000 / 55379 : 56.4400444031 (55.282968998s)\n",
      "34000 / 55379 : 57.895450592 (94.3811018467s)\n",
      "35000 / 55379 : 56.6536407471 (57.8157281876s)\n",
      "36000 / 55379 : 56.6410980225 (56.053098917s)\n",
      "37000 / 55379 : 57.1975135803 (61.9075679779s)\n",
      "38000 / 55379 : 56.0215263367 (55.7781028748s)\n",
      "39000 / 55379 : 55.6667098999 (48.4636030197s)\n",
      "40000 / 55379 : 57.029045105 (70.1101870537s)\n",
      "41000 / 55379 : 55.8811607361 (66.1784050465s)\n",
      "42000 / 55379 : 59.0529518127 (69.4404430389s)\n",
      "43000 / 55379 : 56.1190795898 (68.4497129917s)\n",
      "44000 / 55379 : 55.9122581482 (68.8467569351s)\n",
      "45000 / 55379 : 57.4972076416 (76.1446561813s)\n",
      "46000 / 55379 : 57.3516921997 (60.2230989933s)\n",
      "47000 / 55379 : 56.2638626099 (56.8052401543s)\n",
      "48000 / 55379 : 57.2762680054 (62.4616911411s)\n",
      "49000 / 55379 : 56.3150901794 (63.27344203s)\n",
      "50000 / 55379 : 54.727191925 (59.3101129532s)\n",
      "51000 / 55379 : 56.2524681091 (54.8180689812s)\n",
      "52000 / 55379 : 56.4600563049 (56.736656189s)\n",
      "53000 / 55379 : 55.7165985107 (57.6351091862s)\n",
      "54000 / 55379 : 54.3363342285 (64.3855450153s)\n",
      "55000 / 55379 : 53.6497840881 (66.1780600548s)\n",
      "Epoch completed in 3579.88619089 seconds\n",
      "Train Acc: 0.164340273389 Val Acc: 0.167166666667 Val Loss: 361.08380127\n",
      "Epoch 3 / 10\n",
      "0 / 55379 : 5.27681350708 (1.45875597s)\n",
      "1000 / 55379 : 55.490776062 (58.1033551693s)\n",
      "2000 / 55379 : 56.7805404663 (54.9533650875s)\n",
      "3000 / 55379 : 53.7097511292 (51.3810200691s)\n",
      "4000 / 55379 : 55.6658096313 (58.2607660294s)\n",
      "5000 / 55379 : 53.008682251 (52.3174459934s)\n",
      "6000 / 55379 : 52.9373779297 (62.05032897s)\n",
      "7000 / 55379 : 54.8792495728 (71.0852398872s)\n",
      "8000 / 55379 : 53.6298599243 (55.5917229652s)\n",
      "9000 / 55379 : 55.4558868408 (66.3145370483s)\n",
      "10000 / 55379 : 53.6335372925 (64.7207770348s)\n",
      "11000 / 55379 : 52.9642524719 (58.7063839436s)\n",
      "12000 / 55379 : 54.3199920654 (53.4152028561s)\n",
      "13000 / 55379 : 53.691860199 (59.6456501484s)\n",
      "14000 / 55379 : 51.7879180908 (50.221216917s)\n",
      "15000 / 55379 : 53.6526489258 (61.354268074s)\n",
      "16000 / 55379 : 51.690864563 (66.0651810169s)\n",
      "17000 / 55379 : 52.627117157 (68.3823881149s)\n",
      "18000 / 55379 : 52.6341094971 (68.5724570751s)\n",
      "19000 / 55379 : 51.1693572998 (58.6636779308s)\n",
      "20000 / 55379 : 50.4622573853 (64.353662014s)\n",
      "21000 / 55379 : 53.0950126648 (50.914481163s)\n",
      "22000 / 55379 : 49.4177780151 (67.9925670624s)\n",
      "23000 / 55379 : 50.3761787415 (67.2692840099s)\n",
      "24000 / 55379 : 51.8423881531 (60.0791962147s)\n",
      "25000 / 55379 : 50.5217323303 (55.4078178406s)\n",
      "26000 / 55379 : 50.477180481 (53.2629010677s)\n",
      "27000 / 55379 : 50.5725708008 (60.9894709587s)\n",
      "28000 / 55379 : 49.0673980713 (74.7119619846s)\n",
      "29000 / 55379 : 50.7115859985 (65.6386401653s)\n",
      "30000 / 55379 : 49.8279647827 (77.7820699215s)\n",
      "31000 / 55379 : 47.4146766663 (59.6624078751s)\n",
      "32000 / 55379 : 50.9311981201 (67.1248779297s)\n",
      "33000 / 55379 : 48.4836921692 (55.1533441544s)\n",
      "34000 / 55379 : 50.3366203308 (91.2615671158s)\n",
      "35000 / 55379 : 49.0129356384 (56.4623668194s)\n",
      "36000 / 55379 : 49.0547218323 (53.4517948627s)\n",
      "37000 / 55379 : 49.2792205811 (59.6447169781s)\n",
      "38000 / 55379 : 48.8831748962 (52.9119000435s)\n",
      "39000 / 55379 : 48.438293457 (47.1442120075s)\n",
      "40000 / 55379 : 49.7920188904 (68.261685133s)\n",
      "41000 / 55379 : 48.1244087219 (65.0915398598s)\n",
      "42000 / 55379 : 52.3441810608 (66.700371027s)\n",
      "43000 / 55379 : 48.6297302246 (66.0355141163s)\n",
      "44000 / 55379 : 48.8513031006 (64.5052390099s)\n",
      "45000 / 55379 : 49.2521629333 (74.0915689468s)\n",
      "46000 / 55379 : 49.8662872314 (58.8046472073s)\n",
      "47000 / 55379 : 49.1335372925 (56.5547840595s)\n",
      "48000 / 55379 : 50.4410705566 (62.6223330498s)\n",
      "49000 / 55379 : 49.2372932434 (61.9639010429s)\n",
      "50000 / 55379 : 46.6280822754 (58.6231560707s)\n",
      "51000 / 55379 : 48.7933235168 (55.2153918743s)\n",
      "52000 / 55379 : 49.9932823181 (58.4104700089s)\n",
      "53000 / 55379 : 48.8063812256 (58.7851560116s)\n",
      "54000 / 55379 : 47.3545684814 (64.9735429287s)\n",
      "55000 / 55379 : 47.0881614685 (65.5574469566s)\n",
      "Epoch completed in 3503.28405285 seconds\n",
      "Train Acc: 0.223749074559 Val Acc: 0.175666666667 Val Loss: 363.24810791\n",
      "Epoch 4 / 10\n",
      "0 / 55379 : 4.71653556824 (1.07189798355s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 55379 : 48.7000808716 (54.7801480293s)\n",
      "2000 / 55379 : 49.9173355103 (55.0574731827s)\n",
      "3000 / 55379 : 46.2265701294 (51.9855880737s)\n",
      "4000 / 55379 : 49.0157432556 (57.5629279613s)\n",
      "5000 / 55379 : 45.5749435425 (55.2005410194s)\n",
      "6000 / 55379 : 46.8113059998 (61.6495170593s)\n",
      "7000 / 55379 : 47.5884208679 (70.7072069645s)\n",
      "8000 / 55379 : 46.7803001404 (56.2333338261s)\n",
      "9000 / 55379 : 48.2916717529 (69.8208031654s)\n",
      "10000 / 55379 : 46.637298584 (65.4275538921s)\n",
      "11000 / 55379 : 45.8914146423 (58.9065279961s)\n",
      "12000 / 55379 : 48.3684768677 (52.7781579494s)\n",
      "13000 / 55379 : 46.740398407 (60.411482811s)\n",
      "14000 / 55379 : 45.8810768127 (49.3154909611s)\n",
      "15000 / 55379 : 46.7668533325 (59.4710268974s)\n",
      "16000 / 55379 : 45.1015434265 (64.3995251656s)\n",
      "17000 / 55379 : 46.2174530029 (68.088078022s)\n",
      "18000 / 55379 : 46.3317832947 (67.5236690044s)\n",
      "19000 / 55379 : 43.5160942078 (58.5927448273s)\n",
      "20000 / 55379 : 43.4332466125 (64.257625103s)\n",
      "21000 / 55379 : 45.8598518372 (50.3952858448s)\n",
      "22000 / 55379 : 42.101852417 (65.5500261784s)\n",
      "23000 / 55379 : 43.7587814331 (66.5704090595s)\n",
      "24000 / 55379 : 45.7584114075 (58.0430920124s)\n",
      "25000 / 55379 : 43.5417747498 (54.9060070515s)\n",
      "26000 / 55379 : 44.6009216309 (52.6165721416s)\n",
      "27000 / 55379 : 43.9837188721 (58.3046529293s)\n",
      "28000 / 55379 : 42.2000617981 (72.3090939522s)\n",
      "29000 / 55379 : 44.7666740417 (63.1428639889s)\n",
      "30000 / 55379 : 43.4746360779 (75.7919371128s)\n",
      "31000 / 55379 : 41.1135635376 (57.9795310497s)\n",
      "32000 / 55379 : 45.0645294189 (63.7977859974s)\n",
      "33000 / 55379 : 42.1214561462 (54.4700508118s)\n",
      "34000 / 55379 : 43.3758926392 (89.0416939259s)\n",
      "35000 / 55379 : 42.4013252258 (55.7979660034s)\n",
      "36000 / 55379 : 42.4947967529 (52.6297311783s)\n",
      "37000 / 55379 : 42.1217193604 (60.6598570347s)\n",
      "38000 / 55379 : 42.763168335 (52.7242879868s)\n",
      "39000 / 55379 : 42.1480026245 (46.8548481464s)\n",
      "40000 / 55379 : 43.0024757385 (67.0742251873s)\n",
      "41000 / 55379 : 41.5660743713 (63.0700728893s)\n",
      "42000 / 55379 : 46.2611236572 (66.0704221725s)\n",
      "43000 / 55379 : 41.86977005 (63.9841229916s)\n",
      "44000 / 55379 : 42.9709663391 (64.5177159309s)\n",
      "45000 / 55379 : 41.7293357849 (73.7373290062s)\n",
      "46000 / 55379 : 43.4619674683 (58.6755440235s)\n",
      "47000 / 55379 : 42.7833824158 (57.2647049427s)\n",
      "48000 / 55379 : 44.2758827209 (61.299421072s)\n",
      "49000 / 55379 : 42.8034248352 (61.8860509396s)\n",
      "50000 / 55379 : 39.7230415344 (58.5655550957s)\n",
      "51000 / 55379 : 42.3293075562 (54.9542908669s)\n",
      "52000 / 55379 : 43.8438186646 (56.4091978073s)\n",
      "53000 / 55379 : 42.7227668762 (55.619300127s)\n",
      "54000 / 55379 : 40.9617195129 (63.3255178928s)\n",
      "55000 / 55379 : 41.3608169556 (63.0143709183s)\n",
      "Epoch completed in 3452.17383099 seconds\n",
      "Train Acc: 0.278950504704 Val Acc: 0.178333333333 Val Loss: 383.348205566\n",
      "Epoch 5 / 10\n",
      "0 / 55379 : 4.2612991333 (1.28632712364s)\n",
      "1000 / 55379 : 43.0836601257 (53.5686750412s)\n",
      "2000 / 55379 : 43.9712524414 (53.8801472187s)\n",
      "3000 / 55379 : 39.1140556335 (50.3163180351s)\n",
      "4000 / 55379 : 43.2037658691 (57.0871658325s)\n",
      "5000 / 55379 : 38.9531974792 (52.0446138382s)\n",
      "6000 / 55379 : 40.936870575 (60.2635068893s)\n",
      "7000 / 55379 : 40.6498298645 (69.8346159458s)\n",
      "8000 / 55379 : 40.5965843201 (54.6161940098s)\n",
      "9000 / 55379 : 41.6349868774 (66.2580699921s)\n",
      "10000 / 55379 : 39.972114563 (64.3664240837s)\n",
      "11000 / 55379 : 39.4110565186 (57.9189450741s)\n",
      "12000 / 55379 : 42.4694633484 (51.6114621162s)\n",
      "13000 / 55379 : 40.2095909119 (59.3389370441s)\n",
      "14000 / 55379 : 40.5016746521 (48.4648981094s)\n",
      "15000 / 55379 : 40.0535125732 (59.0403010845s)\n",
      "16000 / 55379 : 39.5433197021 (63.7371349335s)\n",
      "17000 / 55379 : 40.5315628052 (66.5461580753s)\n",
      "18000 / 55379 : 40.9199447632 (66.1364519596s)\n",
      "19000 / 55379 : 37.2336120605 (59.1628730297s)\n",
      "20000 / 55379 : 36.7700119019 (64.704846859s)\n",
      "21000 / 55379 : 39.471862793 (49.759868145s)\n",
      "22000 / 55379 : 35.1196365356 (65.6259579659s)\n",
      "23000 / 55379 : 37.8490486145 (65.2769081593s)\n",
      "24000 / 55379 : 39.8764801025 (58.5978150368s)\n",
      "25000 / 55379 : 36.5018196106 (54.3464069366s)\n",
      "26000 / 55379 : 39.5036888123 (52.6750571728s)\n",
      "27000 / 55379 : 36.8610534668 (58.4508209229s)\n",
      "28000 / 55379 : 37.4397010803 (71.5497369766s)\n",
      "29000 / 55379 : 38.27501297 (63.7650401592s)\n",
      "30000 / 55379 : 37.8171081543 (75.5754790306s)\n",
      "31000 / 55379 : 35.586101532 (57.5429439545s)\n",
      "32000 / 55379 : 39.1754837036 (63.9744169712s)\n",
      "33000 / 55379 : 36.483253479 (53.303207159s)\n",
      "34000 / 55379 : 37.625629425 (89.2275290489s)\n",
      "35000 / 55379 : 36.6553916931 (56.4894480705s)\n",
      "36000 / 55379 : 36.3637123108 (52.3496711254s)\n",
      "37000 / 55379 : 36.4272842407 (60.1631250381s)\n",
      "38000 / 55379 : 36.8635902405 (52.184057951s)\n",
      "39000 / 55379 : 36.4723854065 (46.5892820358s)\n",
      "40000 / 55379 : 37.4843254089 (66.3374481201s)\n",
      "41000 / 55379 : 35.8296165466 (63.2860620022s)\n",
      "42000 / 55379 : 40.7705345154 (66.5930531025s)\n",
      "43000 / 55379 : 36.3722000122 (63.58031106s)\n",
      "44000 / 55379 : 37.5271224976 (63.690819025s)\n",
      "45000 / 55379 : 35.3758239746 (72.8258030415s)\n",
      "46000 / 55379 : 38.2782363892 (57.8713309765s)\n",
      "47000 / 55379 : 36.7643127441 (54.8912370205s)\n",
      "48000 / 55379 : 38.3495903015 (59.9187400341s)\n",
      "49000 / 55379 : 36.5233039856 (60.6055870056s)\n",
      "50000 / 55379 : 34.0708007812 (57.6425709724s)\n",
      "51000 / 55379 : 36.5797233582 (53.3459279537s)\n",
      "52000 / 55379 : 38.387348175 (56.6632859707s)\n",
      "53000 / 55379 : 38.0206298828 (55.6368129253s)\n",
      "54000 / 55379 : 35.4168968201 (64.5497009754s)\n",
      "55000 / 55379 : 35.6903991699 (63.8616809845s)\n",
      "Epoch completed in 3415.86026812 seconds\n",
      "Train Acc: 0.333935246212 Val Acc: 0.166666666667 Val Loss: 417.558044434\n",
      "Epoch 6 / 10\n",
      "0 / 55379 : 3.62279415131 (1.29524207115s)\n",
      "1000 / 55379 : 37.6777153015 (53.9564189911s)\n",
      "2000 / 55379 : 38.6848983765 (54.6758551598s)\n",
      "3000 / 55379 : 33.2899894714 (51.1269459724s)\n",
      "4000 / 55379 : 37.6936340332 (55.2543029785s)\n",
      "5000 / 55379 : 33.6983833313 (50.8642501831s)\n",
      "6000 / 55379 : 36.2668418884 (59.95779109s)\n",
      "7000 / 55379 : 34.9104156494 (68.297000885s)\n",
      "8000 / 55379 : 35.2509078979 (55.1119880676s)\n",
      "9000 / 55379 : 36.2028007507 (66.7992260456s)\n",
      "10000 / 55379 : 33.3238830566 (64.5767900944s)\n",
      "11000 / 55379 : 34.499256134 (59.1777698994s)\n",
      "12000 / 55379 : 37.0394821167 (50.3793349266s)\n",
      "13000 / 55379 : 34.3598632812 (59.4215528965s)\n",
      "14000 / 55379 : 35.9489250183 (48.2062299252s)\n",
      "15000 / 55379 : 33.9514007568 (57.9018850327s)\n",
      "16000 / 55379 : 35.2330627441 (63.1367950439s)\n",
      "17000 / 55379 : 35.0044059753 (66.2079739571s)\n",
      "18000 / 55379 : 36.2873878479 (66.8461670876s)\n",
      "19000 / 55379 : 31.7273597717 (57.3703479767s)\n",
      "20000 / 55379 : 32.0959320068 (65.0889298916s)\n",
      "21000 / 55379 : 34.2711410522 (50.0770938396s)\n",
      "22000 / 55379 : 29.4921951294 (65.0484879017s)\n",
      "23000 / 55379 : 33.2524719238 (65.4578540325s)\n",
      "24000 / 55379 : 34.35206604 (58.6000628471s)\n",
      "25000 / 55379 : 30.2714862823 (54.6649591923s)\n",
      "26000 / 55379 : 34.7414398193 (51.8339428902s)\n",
      "27000 / 55379 : 31.8923187256 (57.4788320065s)\n",
      "28000 / 55379 : 32.8947753906 (71.7540178299s)\n",
      "29000 / 55379 : 32.4583930969 (63.7828941345s)\n",
      "30000 / 55379 : 33.4994621277 (75.0311129093s)\n",
      "31000 / 55379 : 30.2586364746 (56.5797011852s)\n",
      "32000 / 55379 : 34.1959495544 (63.6216170788s)\n",
      "33000 / 55379 : 31.3304443359 (52.944849968s)\n",
      "34000 / 55379 : 33.0724868774 (89.0935680866s)\n",
      "35000 / 55379 : 31.393157959 (56.8291420937s)\n",
      "36000 / 55379 : 30.9752311707 (52.5335030556s)\n",
      "37000 / 55379 : 32.6138954163 (60.0023038387s)\n",
      "38000 / 55379 : 32.6740150452 (53.090793848s)\n",
      "39000 / 55379 : 31.3584327698 (47.1873369217s)\n",
      "40000 / 55379 : 32.1882133484 (66.5069079399s)\n",
      "41000 / 55379 : 30.9964237213 (64.2627489567s)\n",
      "42000 / 55379 : 35.6812286377 (66.6691961288s)\n",
      "43000 / 55379 : 32.7730789185 (63.3280210495s)\n",
      "44000 / 55379 : 33.0890007019 (64.1692681313s)\n",
      "45000 / 55379 : 30.9869270325 (73.3558411598s)\n",
      "46000 / 55379 : 34.3486404419 (57.548979044s)\n",
      "47000 / 55379 : 33.4897193909 (55.7674770355s)\n",
      "48000 / 55379 : 34.3641242981 (61.8608028889s)\n",
      "49000 / 55379 : 32.4377861023 (61.9329638481s)\n",
      "50000 / 55379 : 30.5867481232 (58.9422171116s)\n",
      "51000 / 55379 : 31.4534034729 (56.2801811695s)\n",
      "52000 / 55379 : 34.1175613403 (57.5308890343s)\n",
      "53000 / 55379 : 34.7220954895 (55.6764700413s)\n",
      "54000 / 55379 : 32.7364578247 (64.5276741982s)\n",
      "55000 / 55379 : 33.2427597046 (63.9075450897s)\n",
      "Epoch completed in 3420.20500588 seconds\n",
      "Train Acc: 0.380866393398 Val Acc: 0.16 Val Loss: 477.916015625\n",
      "Epoch 7 / 10\n",
      "0 / 55379 : 3.22581100464 (1.29594898224s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 55379 : 33.7910499573 (53.6627922058s)\n",
      "2000 / 55379 : 33.9386062622 (54.3274800777s)\n",
      "3000 / 55379 : 30.3726177216 (50.3086872101s)\n",
      "4000 / 55379 : 32.8598518372 (55.5951399803s)\n",
      "5000 / 55379 : 30.0011558533 (54.0198040009s)\n",
      "6000 / 55379 : 31.9508686066 (60.2853460312s)\n",
      "7000 / 55379 : 30.9251270294 (67.337624073s)\n",
      "8000 / 55379 : 31.4829769135 (55.1966969967s)\n",
      "9000 / 55379 : 32.2314033508 (67.2500901222s)\n",
      "10000 / 55379 : 29.5034294128 (64.9019348621s)\n",
      "11000 / 55379 : 31.2685089111 (59.7315981388s)\n",
      "12000 / 55379 : 33.0707893372 (51.393504858s)\n",
      "13000 / 55379 : 31.3075714111 (59.2780401707s)\n",
      "14000 / 55379 : 33.1058769226 (48.0564110279s)\n",
      "15000 / 55379 : 30.5146846771 (57.3733539581s)\n",
      "16000 / 55379 : 30.7495155334 (64.3561811447s)\n",
      "17000 / 55379 : 30.7119617462 (66.5166928768s)\n",
      "18000 / 55379 : 33.0079841614 (67.6175320148s)\n",
      "19000 / 55379 : 28.4821815491 (57.0835490227s)\n",
      "20000 / 55379 : 29.2808094025 (62.8923327923s)\n",
      "21000 / 55379 : 30.7523498535 (49.3352768421s)\n",
      "22000 / 55379 : 27.153181076 (66.3174300194s)\n",
      "23000 / 55379 : 30.201839447 (67.1749138832s)\n",
      "24000 / 55379 : 32.4672203064 (57.7726750374s)\n",
      "25000 / 55379 : 26.8815937042 (54.300673008s)\n",
      "26000 / 55379 : 31.6230049133 (51.4092640877s)\n",
      "27000 / 55379 : 29.242816925 (58.2270309925s)\n",
      "28000 / 55379 : 29.2662811279 (71.5094969273s)\n",
      "29000 / 55379 : 28.9466819763 (63.7633149624s)\n",
      "30000 / 55379 : 30.6389102936 (76.0892989635s)\n",
      "31000 / 55379 : 26.0057868958 (57.89884305s)\n",
      "32000 / 55379 : 30.5254096985 (64.0319261551s)\n",
      "33000 / 55379 : 29.209186554 (52.8523938656s)\n",
      "34000 / 55379 : 30.4989643097 (89.0512571335s)\n",
      "35000 / 55379 : 29.361207962 (56.0425281525s)\n",
      "36000 / 55379 : 27.5811576843 (52.6947000027s)\n",
      "37000 / 55379 : 28.249130249 (59.1153888702s)\n",
      "38000 / 55379 : 28.2610816956 (52.6325099468s)\n",
      "39000 / 55379 : 27.7830638885 (46.9503059387s)\n",
      "40000 / 55379 : 28.8273067474 (67.619273901s)\n",
      "41000 / 55379 : 28.8527145386 (64.0022490025s)\n",
      "42000 / 55379 : 32.5946464539 (66.4790611267s)\n",
      "43000 / 55379 : 30.2884540558 (63.2497859001s)\n",
      "44000 / 55379 : 29.608745575 (64.2025370598s)\n",
      "45000 / 55379 : 27.8256587982 (72.6587789059s)\n",
      "46000 / 55379 : 30.4791183472 (57.9786539078s)\n",
      "47000 / 55379 : 30.6211013794 (55.4986522198s)\n",
      "48000 / 55379 : 30.813703537 (60.7560229301s)\n",
      "49000 / 55379 : 30.9794120789 (62.3180840015s)\n",
      "50000 / 55379 : 28.9029388428 (59.6958818436s)\n",
      "51000 / 55379 : 28.8258018494 (54.0272290707s)\n",
      "52000 / 55379 : 32.7213745117 (57.2866151333s)\n",
      "53000 / 55379 : 32.5948562622 (56.0658771992s)\n",
      "54000 / 55379 : 30.1809177399 (63.9374570847s)\n",
      "55000 / 55379 : 28.3438434601 (62.4877178669s)\n",
      "Epoch completed in 3420.71158314 seconds\n",
      "Train Acc: 0.415193484895 Val Acc: 0.155 Val Loss: 506.93737793\n",
      "Epoch 8 / 10\n",
      "0 / 55379 : 2.84767007828 (1.0189781189s)\n",
      "1000 / 55379 : 30.4498443604 (52.8263540268s)\n",
      "2000 / 55379 : 30.8826122284 (54.7196400166s)\n",
      "3000 / 55379 : 27.5372524261 (49.4518909454s)\n",
      "4000 / 55379 : 28.6812725067 (56.1258049011s)\n",
      "5000 / 55379 : 28.3308887482 (51.9914519787s)\n",
      "6000 / 55379 : 29.4121856689 (61.2605960369s)\n",
      "7000 / 55379 : 28.3199958801 (68.1835429668s)\n",
      "8000 / 55379 : 28.3370742798 (55.6597509384s)\n",
      "9000 / 55379 : 30.1859378815 (67.0879490376s)\n",
      "10000 / 55379 : 28.3214015961 (66.0816528797s)\n",
      "11000 / 55379 : 28.2694759369 (57.4072859287s)\n",
      "12000 / 55379 : 29.8660793304 (52.1303548813s)\n",
      "13000 / 55379 : 29.4135398865 (60.1281559467s)\n",
      "14000 / 55379 : 28.672044754 (48.6091980934s)\n",
      "15000 / 55379 : 60.3345336914 (58.7031190395s)\n",
      "16000 / 55379 : 92.5214233398 (63.2380461693s)\n",
      "17000 / 55379 : 87.782409668 (66.9120659828s)\n",
      "18000 / 55379 : 80.5121154785 (67.2218940258s)\n",
      "19000 / 55379 : 59.5532684326 (58.9247179031s)\n",
      "20000 / 55379 : 46.9150047302 (63.5859768391s)\n",
      "21000 / 55379 : 45.73097229 (50.4116911888s)\n",
      "22000 / 55379 : 38.3803520203 (66.1077749729s)\n",
      "23000 / 55379 : 38.3407440186 (65.4957389832s)\n",
      "24000 / 55379 : 37.9902191162 (58.6004021168s)\n",
      "25000 / 55379 : 35.9486274719 (54.4201920033s)\n",
      "26000 / 55379 : 34.7298278809 (52.4335989952s)\n",
      "27000 / 55379 : 34.0178146362 (59.0822930336s)\n",
      "28000 / 55379 : 33.8717041016 (71.7640430927s)\n",
      "29000 / 55379 : 34.2643127441 (64.67527318s)\n",
      "30000 / 55379 : 34.1072044373 (74.1394050121s)\n",
      "31000 / 55379 : 31.8386955261 (57.3176729679s)\n",
      "32000 / 55379 : 33.1277961731 (63.784984827s)\n",
      "33000 / 55379 : 30.8786563873 (53.0249989033s)\n",
      "34000 / 55379 : 32.4044494629 (89.6794340611s)\n",
      "35000 / 55379 : 30.8449192047 (55.8308720589s)\n",
      "36000 / 55379 : 31.3626194 (51.8829782009s)\n",
      "37000 / 55379 : 31.321893692 (59.4214711189s)\n",
      "38000 / 55379 : 32.496761322 (52.1250610352s)\n",
      "39000 / 55379 : 34.4760398865 (48.1729428768s)\n",
      "40000 / 55379 : 38.3290710449 (66.7680351734s)\n",
      "41000 / 55379 : 40.6419334412 (63.1881020069s)\n",
      "42000 / 55379 : 120.173873901 (65.4966142178s)\n",
      "43000 / 55379 : 152.963531494 (64.2970759869s)\n",
      "44000 / 55379 : 426.970428467 (64.3103160858s)\n",
      "45000 / 55379 : 732.765563965 (74.2667338848s)\n",
      "46000 / 55379 : 1048.78735352 (58.7124421597s)\n",
      "47000 / 55379 : 1995.0456543 (55.0241060257s)\n",
      "48000 / 55379 : 5068.84619141 (61.0291180611s)\n",
      "49000 / 55379 : 6313.51513672 (61.4075949192s)\n",
      "50000 / 55379 : 14732.9199219 (57.7165050507s)\n",
      "51000 / 55379 : 41220.4570312 (54.3025610447s)\n",
      "52000 / 55379 : 40577.0234375 (57.2682108879s)\n",
      "53000 / 55379 : 160952.28125 (56.796104908s)\n",
      "54000 / 55379 : 380660.46875 (63.5766000748s)\n",
      "55000 / 55379 : 822931.1875 (63.4018549919s)\n",
      "Epoch completed in 3422.82391787 seconds\n",
      "Train Acc: 0.290019682551 Val Acc: 0.000333333333333 Val Loss: 4254272.0\n",
      "Epoch 9 / 10\n",
      "0 / 55379 : 83585.671875 (1.37250590324s)\n",
      "1000 / 55379 : 908140.0625 (54.591176033s)\n",
      "2000 / 55379 : 684801.875 (55.0676391125s)\n",
      "3000 / 55379 : 1151626.75 (49.4929051399s)\n",
      "4000 / 55379 : 392310.90625 (56.2773048878s)\n",
      "5000 / 55379 : 509810.125 (52.2852518559s)\n",
      "6000 / 55379 : 1250857.0 (60.2988550663s)\n",
      "7000 / 55379 : 1646920.75 (68.5946798325s)\n",
      "8000 / 55379 : 1575260.25 (54.6339070797s)\n",
      "9000 / 55379 : 1157879.5 (67.5291340351s)\n",
      "10000 / 55379 : 1558391.25 (64.6937398911s)\n",
      "11000 / 55379 : 2463482.25 (56.594067812s)\n",
      "12000 / 55379 : 1506396.875 (50.8275289536s)\n",
      "13000 / 55379 : 1222062.75 (59.2622158527s)\n",
      "14000 / 55379 : 1629545.875 (48.187267065s)\n",
      "15000 / 55379 : 2687931.0 (58.6640379429s)\n",
      "16000 / 55379 : 2079785.5 (65.1635551453s)\n",
      "17000 / 55379 : 3427519.75 (66.9094450474s)\n",
      "18000 / 55379 : 3585388.5 (66.3022129536s)\n",
      "19000 / 55379 : 1771440.25 (57.4387009144s)\n",
      "20000 / 55379 : 2579563.25 (65.257174015s)\n",
      "21000 / 55379 : 2947185.25 (49.0496959686s)\n",
      "22000 / 55379 : 6120740.0 (65.5480659008s)\n",
      "23000 / 55379 : 2748152.75 (67.0117530823s)\n",
      "24000 / 55379 : 3536894.0 (58.6213998795s)\n",
      "25000 / 55379 : 8905013.0 (54.5153040886s)\n",
      "26000 / 55379 : 7033682.0 (52.8526380062s)\n",
      "27000 / 55379 : 8954330.0 (59.3615500927s)\n",
      "28000 / 55379 : 8193235.5 (71.3679049015s)\n",
      "29000 / 55379 : 7806618.5 (64.8912539482s)\n",
      "30000 / 55379 : 6020296.0 (74.7396399975s)\n",
      "31000 / 55379 : 12604164.0 (58.3262119293s)\n",
      "32000 / 55379 : 22655604.0 (64.8984999657s)\n",
      "33000 / 55379 : 27282178.0 (53.9524810314s)\n",
      "34000 / 55379 : 15613163.0 (89.0183529854s)\n",
      "35000 / 55379 : 36407584.0 (56.7344279289s)\n",
      "36000 / 55379 : 19902964.0 (54.1722679138s)\n",
      "37000 / 55379 : 10495622.0 (58.7633881569s)\n",
      "38000 / 55379 : 12226867.0 (53.2017388344s)\n",
      "39000 / 55379 : 28915906.0 (46.6613359451s)\n",
      "40000 / 55379 : 70372384.0 (66.416301012s)\n",
      "41000 / 55379 : 40750748.0 (64.1108009815s)\n",
      "42000 / 55379 : 47686888.0 (65.3964278698s)\n",
      "43000 / 55379 : 110472408.0 (64.3642930984s)\n",
      "44000 / 55379 : 57677936.0 (63.1385500431s)\n",
      "45000 / 55379 : 39090292.0 (72.7408599854s)\n",
      "46000 / 55379 : 55805452.0 (58.689248085s)\n",
      "47000 / 55379 : 32560464.0 (55.4887111187s)\n",
      "48000 / 55379 : 30472142.0 (60.5922830105s)\n",
      "49000 / 55379 : 14919032.0 (62.0934619904s)\n",
      "50000 / 55379 : 41875444.0 (57.7563579082s)\n",
      "51000 / 55379 : 19172460.0 (53.7250568867s)\n",
      "52000 / 55379 : 39044840.0 (57.124519825s)\n",
      "53000 / 55379 : 18958160.0 (55.4820890427s)\n",
      "54000 / 55379 : 14083592.0 (63.7063970566s)\n",
      "55000 / 55379 : 23419564.0 (63.8694519997s)\n",
      "Epoch completed in 3426.1387229 seconds\n",
      "Train Acc: 0.00317810000181 Val Acc: 0.007 Val Loss: 120133712.0\n",
      "Epoch 10 / 10\n",
      "0 / 55379 : 1409315.625 (1.32815504074s)\n",
      "1000 / 55379 : 35312036.0 (53.4395589828s)\n",
      "2000 / 55379 : 22340782.0 (54.8828589916s)\n",
      "3000 / 55379 : 27828764.0 (49.363822937s)\n",
      "4000 / 55379 : 26579034.0 (55.6082470417s)\n",
      "5000 / 55379 : 67075572.0 (51.1325290203s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 / 55379 : 54220932.0 (61.3744020462s)\n",
      "7000 / 55379 : 35476000.0 (68.8061637878s)\n",
      "8000 / 55379 : 35739900.0 (54.1542510986s)\n",
      "9000 / 55379 : 48927840.0 (66.4883799553s)\n",
      "10000 / 55379 : 45581404.0 (63.5245370865s)\n",
      "11000 / 55379 : 44188268.0 (56.3059520721s)\n",
      "12000 / 55379 : 44566044.0 (50.8819499016s)\n",
      "13000 / 55379 : 97864016.0 (59.5326330662s)\n",
      "14000 / 55379 : 63657948.0 (49.1714861393s)\n",
      "15000 / 55379 : 59171240.0 (58.3430500031s)\n",
      "16000 / 55379 : 55904760.0 (63.7013380527s)\n",
      "17000 / 55379 : 119446808.0 (66.3565080166s)\n",
      "18000 / 55379 : 93616520.0 (65.9894230366s)\n",
      "19000 / 55379 : 41962024.0 (58.4016139507s)\n",
      "20000 / 55379 : 42703472.0 (64.1826310158s)\n",
      "21000 / 55379 : 34532940.0 (49.7728788853s)\n",
      "22000 / 55379 : 116918984.0 (66.427077055s)\n",
      "23000 / 55379 : 43052204.0 (66.5144739151s)\n",
      "24000 / 55379 : 37143312.0 (59.0803129673s)\n",
      "25000 / 55379 : 55316448.0 (55.3050129414s)\n",
      "26000 / 55379 : 39507032.0 (52.3207449913s)\n",
      "27000 / 55379 : 43656280.0 (59.0747561455s)\n",
      "28000 / 55379 : 75452880.0 (72.0404999256s)\n",
      "29000 / 55379 : 53984344.0 (63.3165581226s)\n",
      "30000 / 55379 : 57843184.0 (74.4841310978s)\n",
      "31000 / 55379 : 50676824.0 (57.5683500767s)\n",
      "32000 / 55379 : 123508384.0 (64.1804139614s)\n",
      "33000 / 55379 : 77608352.0 (53.2024180889s)\n",
      "34000 / 55379 : 84290488.0 (88.9561719894s)\n",
      "35000 / 55379 : 60733000.0 (55.4874060154s)\n",
      "36000 / 55379 : 102803104.0 (52.0518491268s)\n",
      "37000 / 55379 : 47997304.0 (59.4719209671s)\n",
      "38000 / 55379 : 71771224.0 (53.0097720623s)\n",
      "39000 / 55379 : 143000096.0 (47.1636149883s)\n",
      "40000 / 55379 : 114220448.0 (67.3138029575s)\n",
      "41000 / 55379 : 67377448.0 (64.3342480659s)\n",
      "42000 / 55379 : 187213632.0 (66.55666399s)\n",
      "43000 / 55379 : 95393600.0 (63.5449690819s)\n",
      "44000 / 55379 : 81494224.0 (63.3645899296s)\n",
      "45000 / 55379 : 335334816.0 (73.5394690037s)\n",
      "46000 / 55379 : 156899952.0 (58.3520479202s)\n",
      "47000 / 55379 : 181626016.0 (56.0127260685s)\n",
      "48000 / 55379 : 100096464.0 (60.5793759823s)\n",
      "49000 / 55379 : 157052304.0 (61.2148079872s)\n",
      "50000 / 55379 : 110416584.0 (57.4530041218s)\n",
      "51000 / 55379 : 138032784.0 (53.6205480099s)\n",
      "52000 / 55379 : 230770320.0 (56.3505342007s)\n",
      "53000 / 55379 : 158011600.0 (55.7438189983s)\n",
      "54000 / 55379 : 130168632.0 (65.1875059605s)\n",
      "55000 / 55379 : 272730240.0 (63.5853331089s)\n",
      "Epoch completed in 3417.29598308 seconds\n",
      "Train Acc: 0.00725906932231 Val Acc: 0.004 Val Loss: 589228864.0\n"
     ]
    }
   ],
   "source": [
    "train_model(model, opt, 0, 10, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_npz('gpu.model', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(i, batch_size, data):\n",
    "    j = min(i + batch_size, len(data))\n",
    "    \n",
    "    ctx = []\n",
    "    qn = []\n",
    "    ids = []\n",
    "    ctxStrs = []\n",
    "    \n",
    "    cmax = 0\n",
    "    qmax = 0\n",
    "    for k in range(i, j):\n",
    "        c, q, s, e = data[k]\n",
    "        ctx.append(c)\n",
    "        qn.append(q)\n",
    "        ids.append(s)\n",
    "        ctxStrs.append(e)\n",
    "        \n",
    "        cmax = max(cmax, c.shape[1])\n",
    "        qmax = max(qmax, q.shape[1])\n",
    "\n",
    "    cVec = np.zeros((len(ctx), cmax), dtype=np.float32)\n",
    "    qVec = np.zeros((len(ctx), qmax), dtype=np.float32)        \n",
    "    for i in range(len(ctx)):\n",
    "        cVec[i, 0:ctx[i].shape[1]] = ctx[i]\n",
    "        qVec[i, 0:qn[i].shape[1]] = qn[i]\n",
    "    \n",
    "    return Variable(cVec), \\\n",
    "           Variable(qVec), \\\n",
    "           ids, \\\n",
    "           ctxStrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 36790 (1.40163993835s)\n",
      "1000 / 36790 (14.9581708908s)\n",
      "2000 / 36790 (13.9215970039s)\n",
      "3000 / 36790 (13.7998709679s)\n",
      "4000 / 36790 (13.6729888916s)\n",
      "5000 / 36790 (14.3381428719s)\n",
      "6000 / 36790 (13.3973069191s)\n",
      "7000 / 36790 (12.3257830143s)\n",
      "8000 / 36790 (12.3547208309s)\n",
      "9000 / 36790 (12.0773820877s)\n",
      "10000 / 36790 (13.3482880592s)\n",
      "11000 / 36790 (12.6208658218s)\n",
      "12000 / 36790 (15.8270070553s)\n",
      "13000 / 36790 (12.7543549538s)\n",
      "14000 / 36790 (14.1055371761s)\n",
      "15000 / 36790 (13.1785640717s)\n",
      "16000 / 36790 (15.712460041s)\n",
      "17000 / 36790 (11.8376300335s)\n",
      "18000 / 36790 (13.573777914s)\n",
      "19000 / 36790 (17.5041937828s)\n",
      "20000 / 36790 (13.0778388977s)\n",
      "21000 / 36790 (16.0437159538s)\n",
      "22000 / 36790 (13.4823410511s)\n",
      "23000 / 36790 (11.2038550377s)\n",
      "24000 / 36790 (13.0235090256s)\n",
      "25000 / 36790 (14.7025828362s)\n",
      "26000 / 36790 (13.1118619442s)\n",
      "27000 / 36790 (14.967897892s)\n",
      "28000 / 36790 (14.4318180084s)\n",
      "29000 / 36790 (13.5588378906s)\n",
      "30000 / 36790 (18.678992033s)\n",
      "31000 / 36790 (12.8858289719s)\n",
      "32000 / 36790 (15.9406499863s)\n",
      "33000 / 36790 (13.6405799389s)\n",
      "34000 / 36790 (13.951682806s)\n",
      "35000 / 36790 (13.3835980892s)\n",
      "36000 / 36790 (12.2917568684s)\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 100\n",
    "test_print_interval = 1000\n",
    "\n",
    "serializers.load_npz('gpu-epoch3.model', model)\n",
    "\n",
    "f = open('pred3.csv', 'wb')\n",
    "out = csv.writer(f)\n",
    "out.writerow([\"Id\", \"Answer\"])\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for i in range(0, len(test), test_batch_size):\n",
    "    ctx, qn, qnId, ctxStr = get_test_batch(i, test_batch_size, test)\n",
    "    model.reset_state()\n",
    "    start, end = model(ctx, qn)\n",
    "\n",
    "    for j in range(len(qnId)):\n",
    "        contextTokens = word_tokenize(ctxStr[j])\n",
    "\n",
    "        s = F.argmax(start[j]).data\n",
    "        e = F.argmax(end[j]).data\n",
    "        \n",
    "        s = min(s, len(contextTokens)-1)\n",
    "        e = max(e, s)\n",
    "        e = min(e, len(contextTokens)-1)        \n",
    "        \n",
    "        ans = \"\"\n",
    "        for k in range(s, e + 1):\n",
    "            ans += contextTokens[k] + \" \"\n",
    "        \n",
    "        out.writerow([qnId[j], normalize_answer(ans).encode('utf-8')])\n",
    "    \n",
    "    if i % test_print_interval == 0:\n",
    "        print i, \"/\", len(test), \"(\" + str(time.time() - startTime) + \"s)\"\n",
    "        startTime = time.time()\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
